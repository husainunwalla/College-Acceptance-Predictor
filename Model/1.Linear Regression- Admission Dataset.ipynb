{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- ### The goal here is to find the chance of admission of a candidate based on his/her GRE score, TOEFL score, rating of the university in which he/she is trying to get admission,strength of the SOP,Strength of the letter of the recommendation, CGPA and the research experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Prediction.csv\")  # importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRE Score'].fillna(df['GRE Score'].mode()[0],inplace=True)\n",
    "df['TOEFL Score'].fillna(df['TOEFL Score'].mode()[0],inplace=True)\n",
    "df['University Rating'].fillna(df['University Rating'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4.3</th>\n",
       "      <td>311.285714</td>\n",
       "      <td>103.857143</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>8.434286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.5</th>\n",
       "      <td>317.833333</td>\n",
       "      <td>104.833333</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>8.973333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.9</th>\n",
       "      <td>315.333333</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>3.683333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>8.495000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.6</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>3.683333</td>\n",
       "      <td>3.483333</td>\n",
       "      <td>7.683333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.4</th>\n",
       "      <td>310.500000</td>\n",
       "      <td>105.666667</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>8.076667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.6</th>\n",
       "      <td>313.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.7</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>100.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>6.776667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82.3</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.0</th>\n",
       "      <td>293.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GRE Score  TOEFL Score       SOP       LOR      CGPA  \\\n",
       "University Rating                                                          \n",
       "4.3                311.285714   103.857143  3.428571  3.428571  8.434286   \n",
       "15.0               317.000000   110.000000  3.000000  3.000000  8.880000   \n",
       "16.0               317.000000   110.000000  3.000000  3.000000  8.880000   \n",
       "17.5               317.833333   104.833333  4.083333  4.083333  8.973333   \n",
       "20.0               317.000000   110.000000  3.000000  3.000000  8.880000   \n",
       "29.9               315.333333   106.000000  3.683333  4.066667  8.495000   \n",
       "36.6               316.000000   107.833333  3.683333  3.483333  7.683333   \n",
       "46.4               310.500000   105.666667  3.583333  3.566667  8.076667   \n",
       "47.0               317.000000   110.000000  3.000000  3.000000  8.880000   \n",
       "63.6               313.000000   104.000000  3.000000  3.000000  7.950000   \n",
       "70.7               303.000000   100.833333  3.333333  3.666667  6.776667   \n",
       "82.3               292.000000    87.000000  1.333333  1.333333  7.900000   \n",
       "99.0               293.000000    92.000000  1.000000  1.000000  6.000000   \n",
       "\n",
       "                   Research  Chance of Admit  \n",
       "University Rating                             \n",
       "4.3                0.571429         0.428571  \n",
       "15.0               0.000000         0.000000  \n",
       "16.0               0.000000         0.000000  \n",
       "17.5               0.666667         0.500000  \n",
       "20.0               0.000000         1.000000  \n",
       "29.9               0.333333         0.500000  \n",
       "36.6               0.333333         0.500000  \n",
       "46.4               0.500000         0.500000  \n",
       "47.0               0.000000         1.000000  \n",
       "63.6               0.500000         0.500000  \n",
       "70.7               0.500000         0.500000  \n",
       "82.3               0.000000         0.333333  \n",
       "99.0               0.000000         1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_university = df.groupby(by='University Rating').mean()\n",
    "df_university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Chance of Admit'],axis=1)\n",
    "y=df['Chance of Admit']\n",
    "# here we are droping the Chance of Admit and serial no, as they are not going to be used for the features \n",
    "# Chance of Admit is the target column which shows the probalility of admission for a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research\n",
       "0        317          110               47.0  3.0  3.0  8.88         0\n",
       "1        317          110               16.0  3.0  3.0  8.88         0\n",
       "2        317          110                4.3  3.0  3.0  8.88         0\n",
       "3        317          110               20.0  3.0  3.0  8.88         0\n",
       "4        317          110               15.0  3.0  3.0  8.88         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head() # checking the transformed feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5046682 ,  0.71321961,  0.2973651 , -0.33885875, -0.36556246,\n",
       "         0.759955  , -0.8304548 ],\n",
       "       [ 0.5046682 ,  0.71321961, -0.93007399, -0.33885875, -0.36556246,\n",
       "         0.759955  , -0.8304548 ],\n",
       "       [ 0.5046682 ,  0.71321961, -1.39333325, -0.33885875, -0.36556246,\n",
       "         0.759955  , -0.8304548 ],\n",
       "       [ 0.5046682 ,  0.71321961, -0.77169475, -0.33885875, -0.36556246,\n",
       "         0.759955  , -0.8304548 ],\n",
       "       [ 0.5046682 ,  0.71321961, -0.9696688 , -0.33885875, -0.36556246,\n",
       "         0.759955  , -0.8304548 ],\n",
       "       [-1.54892975, -1.36288499,  2.35629518, -2.388745  , -2.23145416,\n",
       "        -1.98779928, -0.8304548 ],\n",
       "       [-1.80562949, -1.59356328,  1.69506186, -1.36380187, -1.29850831,\n",
       "        -0.55667726, -0.8304548 ],\n",
       "       [-1.03553026, -1.59356328,  1.69506186, -2.388745  , -2.23145416,\n",
       "         0.30199595, -0.8304548 ],\n",
       "       [-2.06232924, -2.63161559,  1.69506186, -2.388745  , -2.23145416,\n",
       "        -0.27045286, -0.8304548 ],\n",
       "       [ 1.4459006 ,  0.71321961,  0.95463893, -0.33885875, -0.36556246,\n",
       "        -0.30861611, -0.8304548 ],\n",
       "       [ 0.16240188, -0.44017184,  0.95463893, -0.33885875, -0.36556246,\n",
       "        -0.27045286,  1.20415946],\n",
       "       [-0.8643971 , -0.90152842,  0.95463893, -0.33885875,  0.56738339,\n",
       "         0.29245514,  1.20415946],\n",
       "       [-0.09429787,  0.71321961,  0.95463893, -0.33885875, -1.29850831,\n",
       "        -0.22274879, -0.8304548 ],\n",
       "       [ 1.78816693,  0.71321961, -1.39333325,  0.68608438,  0.56738339,\n",
       "         0.62638361,  1.20415946],\n",
       "       [-0.00873128,  0.13652389, -1.39333325,  1.7110275 ,  1.50032924,\n",
       "         1.30378137,  1.20415946],\n",
       "       [ 0.84693453,  0.9438979 , -1.39333325,  0.68608438,  0.56738339,\n",
       "         0.96031208,  1.20415946],\n",
       "       [-0.94996368, -1.59356328, -1.39333325, -0.33885875, -0.36556246,\n",
       "         0.11117968,  1.20415946],\n",
       "       [-0.94996368, -0.44017184, -1.39333325, -1.36380187, -0.36556246,\n",
       "        -0.70933028, -0.8304548 ],\n",
       "       [-1.12109684, -0.44017184, -1.39333325, -0.33885875, -1.29850831,\n",
       "        -0.70933028, -0.8304548 ],\n",
       "       [ 1.18920086, -0.44017184,  1.23576208, -0.33885875,  0.56738339,\n",
       "         0.58822036, -0.8304548 ],\n",
       "       [-0.8643971 , -0.44017184,  1.23576208,  0.68608438,  1.50032924,\n",
       "        -1.07188119,  1.20415946],\n",
       "       [-1.46336317,  0.13652389,  1.23576208,  1.7110275 ,  1.50032924,\n",
       "        -0.71887109,  1.20415946],\n",
       "       [-1.37779659, -1.01686756,  1.23576208, -1.36380187, -0.36556246,\n",
       "        -2.87509494, -0.8304548 ],\n",
       "       [-0.94996368,  0.71321961,  1.23576208, -0.33885875, -1.29850831,\n",
       "        -2.56024809, -0.8304548 ],\n",
       "       [-0.69326394, -1.01686756,  1.23576208, -0.33885875, -0.36556246,\n",
       "        -0.84290166,  1.20415946],\n",
       "       [ 2.04486667,  1.28991533, -0.87068177,  1.7110275 ,  1.50032924,\n",
       "         1.65679147,  1.20415946],\n",
       "       [ 1.18920086,  0.71321961, -0.87068177,  1.7110275 ,  1.50032924,\n",
       "         1.7521996 ,  1.20415946],\n",
       "       [ 1.36033402,  0.48254132, -0.87068177,  1.19855594,  1.03385632,\n",
       "         1.2560773 ,  1.20415946],\n",
       "       [-0.35099761, -1.13220671, -0.87068177,  0.68608438, -0.36556246,\n",
       "        -0.74749353,  1.20415946],\n",
       "       [ 0.16240188,  0.36720217, -0.87068177, -0.33885875,  0.56738339,\n",
       "         0.58822036, -0.8304548 ],\n",
       "       [-0.94996368, -1.01686756, -0.87068177, -0.33885875, -0.36556246,\n",
       "         0.58822036, -0.8304548 ],\n",
       "       [ 0.76136795,  0.9438979 , -0.11442092,  0.68608438,  0.56738339,\n",
       "        -0.36586099,  1.20415946],\n",
       "       [ 0.93250111,  0.36720217, -0.11442092,  0.68608438, -0.36556246,\n",
       "        -0.65208539,  1.20415946],\n",
       "       [ 0.84693453,  1.63593277, -0.11442092,  0.68608438,  1.03385632,\n",
       "         0.74087337, -0.8304548 ],\n",
       "       [ 0.24796846,  0.9438979 , -0.11442092, -0.03137581,  0.38079422,\n",
       "        -1.68249325, -0.8304548 ],\n",
       "       [-0.00873128,  0.36720217, -0.11442092,  0.0711185 ,  0.10091047,\n",
       "        -0.7284119 , -0.8304548 ],\n",
       "       [-0.26543103, -1.47822414, -0.11442092,  0.0711185 , -1.20521372,\n",
       "         0.39740409, -0.8304548 ],\n",
       "       [ 0.67580137,  1.40525448, -0.37970614,  1.19855594,  1.03385632,\n",
       "         1.41827113, -0.8304548 ],\n",
       "       [ 0.67580137,  1.75127191, -0.37970614,  0.99356731,  0.75397256,\n",
       "         0.78857744,  1.20415946],\n",
       "       [ 1.27476744,  0.13652389, -0.37970614,  0.68608438,  1.50032924,\n",
       "         0.80765907, -0.8304548 ],\n",
       "       [-0.52213077, -2.17025901, -0.37970614, -0.85133031, -0.83203538,\n",
       "         0.49281222, -0.8304548 ],\n",
       "       [ 1.10363427,  0.13652389, -0.37970614,  0.58359007,  0.84726715,\n",
       "        -0.65208539, -0.8304548 ],\n",
       "       [-1.03553026,  0.25186303, -0.37970614, -0.44135306,  0.47408881,\n",
       "        -0.49943238,  1.20415946],\n",
       "       [ 0.84693453,  0.48254132,  0.27360821,  0.68608438,  0.56738339,\n",
       "        -0.14642228,  1.20415946],\n",
       "       [ 0.59023479,  0.71321961,  0.27360821,  0.68608438,  0.56738339,\n",
       "         0.15888375, -0.8304548 ],\n",
       "       [ 0.41910162,  0.71321961,  0.27360821,  0.891073  ,  0.75397256,\n",
       "         0.9698529 , -0.8304548 ],\n",
       "       [-0.09429787, -0.20949355,  0.27360821,  0.48109575,  0.28749964,\n",
       "        -1.03371793, -0.8304548 ],\n",
       "       [-0.94996368,  0.13652389,  0.27360821,  0.17361282,  0.10091047,\n",
       "        -0.36586099,  1.20415946],\n",
       "       [-1.12109684, -0.55551098,  0.27360821, -1.36380187, -1.29850831,\n",
       "         0.37832246,  1.20415946]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be only used if you want to scale the data,standize the data,if the variation is huge in the dataset\n",
    "# when we have huge variation in the data set\n",
    "# i am not changing the data , i am changing the scale only like taking logs, sqrt--not changing the actual meaning of the data set\n",
    "# variance betweeen the dataset become very low\n",
    "# machine will understand in better way this data  as having low variance in the data set\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_feature=StandardScaler()\n",
    "scaler_lablel=StandardScaler()\n",
    "scaled_data=scaler_feature.fit_transform(x)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.33,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2434400285949736"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.035205\n",
      "TOEFL Score           0.002547\n",
      "University Rating     0.017480\n",
      "SOP                   0.029151\n",
      "LOR                   0.382793\n",
      "CGPA                  0.261578\n",
      "Research              0.428959\n",
      "Feature: 0, Score: 0.03520\n",
      "Feature: 1, Score: 0.00255\n",
      "Feature: 2, Score: 0.01748\n",
      "Feature: 3, Score: 0.02915\n",
      "Feature: 4, Score: 0.38279\n",
      "Feature: 5, Score: 0.26158\n",
      "Feature: 6, Score: 0.42896\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "intercept = reg.intercept_\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = reg.coef_[0]\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.20,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7861401571270124"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#tf.keras.layers.Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                400       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               7650      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 150)               22650     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                7550      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,301\n",
      "Trainable params: 38,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN_model = keras.Sequential()\n",
    "ANN_model.add(Dense(50, input_dim = 7))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(50))\n",
    "ANN_model.add(Activation('linear'))\n",
    "ANN_model.add(Dense(1))\n",
    "ANN_model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 2273.6042 - val_loss: 170.1236\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1125.3259 - val_loss: 59.7124\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1173.7336 - val_loss: 40.3463\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1071.0433 - val_loss: 71.6889\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 723.9583 - val_loss: 43.7827\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 606.9637 - val_loss: 47.8499\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 592.9833 - val_loss: 66.2216\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 451.7481 - val_loss: 56.7040\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 394.9084 - val_loss: 23.5132\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 312.9081 - val_loss: 6.2988\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 291.0312 - val_loss: 1.1072\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 225.7877 - val_loss: 3.3667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 313.9057 - val_loss: 2.0913\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 232.9113 - val_loss: 0.7345\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 208.8029 - val_loss: 3.7279\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 78.5579 - val_loss: 10.4621\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 117.7942 - val_loss: 15.1772\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 120.8374 - val_loss: 15.0963\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 122.9510 - val_loss: 11.9674\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 56.1579 - val_loss: 8.0492\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 104.6758 - val_loss: 4.8674\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 114.5081 - val_loss: 2.8489\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 52.1401 - val_loss: 1.9346\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 34.9283 - val_loss: 1.6812\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 30.6770 - val_loss: 1.5623\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 36.3953 - val_loss: 1.5342\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 65.7217 - val_loss: 1.5333\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 74.2351 - val_loss: 1.4413\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 30.0416 - val_loss: 1.4113\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 28.7655 - val_loss: 1.4241\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 32.6714 - val_loss: 1.4792\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 28.8017 - val_loss: 1.5481\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 34.7900 - val_loss: 1.7149\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 23.5533 - val_loss: 2.0351\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 27.1249 - val_loss: 2.3514\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 28.8902 - val_loss: 2.8058\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 21.1240 - val_loss: 3.3000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 23.8720 - val_loss: 3.2951\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 29.3998 - val_loss: 3.0151\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 19.4464 - val_loss: 2.8702\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 15.4900 - val_loss: 2.8188\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 21.8149 - val_loss: 3.0232\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 29.3342 - val_loss: 3.2164\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 23.3692 - val_loss: 3.1164\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 12.6594 - val_loss: 2.9617\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 19.8180 - val_loss: 2.7220\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 22.5875 - val_loss: 2.4439\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 18.3438 - val_loss: 2.2549\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 14.5714 - val_loss: 1.9336\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 15.7221 - val_loss: 1.6414\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 13.7389 - val_loss: 1.4623\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 15.2239 - val_loss: 1.3204\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 16.8116 - val_loss: 1.2608\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 16.1701 - val_loss: 1.1989\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 24.1721 - val_loss: 1.2115\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 9.5667 - val_loss: 1.2478\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 15.8656 - val_loss: 1.2407\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 11.3304 - val_loss: 1.2490\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 10.7345 - val_loss: 1.2884\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 18.4744 - val_loss: 1.3462\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 14.0189 - val_loss: 1.3890\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.7898 - val_loss: 1.4263\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 12.3067 - val_loss: 1.4604\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 12.0010 - val_loss: 1.4967\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 13.5185 - val_loss: 1.5562\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 8.8244 - val_loss: 1.5665\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 11.7816 - val_loss: 1.5227\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 11.9147 - val_loss: 1.5158\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9.6582 - val_loss: 1.5054\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.4585 - val_loss: 1.4888\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 14.1875 - val_loss: 1.4844\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.8256 - val_loss: 1.5059\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 16.5477 - val_loss: 1.5525\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.7600 - val_loss: 1.5625\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 8.6383 - val_loss: 1.6322\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 9.6928 - val_loss: 1.7169\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 13.9857 - val_loss: 1.7265\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 14.9165 - val_loss: 1.7521\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.9857 - val_loss: 1.7437\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 10.0345 - val_loss: 1.7494\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 6.0966 - val_loss: 1.7814\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 7.2037 - val_loss: 1.7712\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.7890 - val_loss: 1.7674\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.5779 - val_loss: 1.7303\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 6.4967 - val_loss: 1.6942\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 8.9366 - val_loss: 1.6746\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.7586 - val_loss: 1.6579\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 6.5403 - val_loss: 1.6591\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.8596 - val_loss: 1.6611\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 11.5421 - val_loss: 1.6551\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 6.3845 - val_loss: 1.6330\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.5402 - val_loss: 1.5793\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.7012 - val_loss: 1.5199\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.3758 - val_loss: 1.4633\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.9336 - val_loss: 1.4091\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.2739 - val_loss: 1.3691\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 4.2879 - val_loss: 1.3421\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.9621 - val_loss: 1.3488\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.0585 - val_loss: 1.3585\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 6.1997 - val_loss: 1.3652\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = ANN_model.fit(train_x, train_y, epochs = 100, batch_size = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0777\n",
      "Accuracy : -0.0777050256729126\n"
     ]
    }
   ],
   "source": [
    "result = ANN_model.evaluate(test_x, test_y)\n",
    "accuracy_ANN = 1 - result\n",
    "print(\"Accuracy : {}\".format(accuracy_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x204e04ab850>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend(['Training Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decesion Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree builds regression or classification models in the form of a tree structure. \n",
    "# Decision tree breaks down a dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "# The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree_model = DecisionTreeRegressor()\n",
    "decisionTree_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.158730\n",
      "TOEFL Score           0.000000\n",
      "University Rating     0.171958\n",
      "SOP                   0.583333\n",
      "LOR                   0.000000\n",
      "CGPA                  0.085979\n",
      "Research              0.000000\n",
      "Feature: 0, Score: 0.15873\n",
      "Feature: 1, Score: 0.00000\n",
      "Feature: 2, Score: 0.17196\n",
      "Feature: 3, Score: 0.58333\n",
      "Feature: 4, Score: 0.00000\n",
      "Feature: 5, Score: 0.08598\n",
      "Feature: 6, Score: 0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = decisionTree_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6666666666666665"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decisionTree = decisionTree_model.score(test_x, test_y)\n",
    "accuracy_decisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhus\\AppData\\Local\\Temp/ipykernel_14320/2085754441.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_model.fit(train_x, train_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3627500000000017"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForest_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "randomForest_model.fit(train_x, train_y)\n",
    "accuracy_randomforest = randomForest_model.score(test_x, test_y)\n",
    "accuracy_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.410505\n",
      "TOEFL Score           0.027425\n",
      "University Rating     0.123003\n",
      "SOP                   0.289187\n",
      "LOR                   0.108846\n",
      "CGPA                  0.029550\n",
      "Research              0.011484\n",
      "Feature: 0, Score: 0.41050\n",
      "Feature: 1, Score: 0.02742\n",
      "Feature: 2, Score: 0.12300\n",
      "Feature: 3, Score: 0.28919\n",
      "Feature: 4, Score: 0.10885\n",
      "Feature: 5, Score: 0.02955\n",
      "Feature: 6, Score: 0.01148\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = randomForest_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model to the local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename='finalized_model.pickle'\n",
    "#pickle.dump(reg,open(filename,'wb'))\n",
    "dump(randomForest_model, 'filename.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
