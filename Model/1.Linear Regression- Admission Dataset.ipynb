{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admission data set \n",
    "# supervised learning - have both x and y value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- ### The goal here is to find the chance of admission of a candidate based on his/her GRE score, TOEFL score, rating of the university in which he/she is trying to get admission,strength of the SOP,Strength of the letter of the recommendation, CGPA and the research experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Prediction.csv\")  # importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRE Score'].fillna(df['GRE Score'].mode()[0],inplace=True)\n",
    "df['TOEFL Score'].fillna(df['TOEFL Score'].mode()[0],inplace=True)\n",
    "df['University Rating'].fillna(df['University Rating'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>304.156250</td>\n",
       "      <td>99.968750</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>2.406250</td>\n",
       "      <td>7.786875</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.560937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.000000</th>\n",
       "      <td>309.548387</td>\n",
       "      <td>103.685484</td>\n",
       "      <td>2.689516</td>\n",
       "      <td>2.955645</td>\n",
       "      <td>8.186452</td>\n",
       "      <td>0.298387</td>\n",
       "      <td>0.627339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.000000</th>\n",
       "      <td>315.032468</td>\n",
       "      <td>106.292208</td>\n",
       "      <td>3.321429</td>\n",
       "      <td>3.405844</td>\n",
       "      <td>8.504545</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.703701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.121649</th>\n",
       "      <td>315.133333</td>\n",
       "      <td>105.600000</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>8.346667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.000000</th>\n",
       "      <td>323.213592</td>\n",
       "      <td>111.087379</td>\n",
       "      <td>3.990291</td>\n",
       "      <td>3.956311</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.801553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.000000</th>\n",
       "      <td>327.236111</td>\n",
       "      <td>113.486111</td>\n",
       "      <td>4.472222</td>\n",
       "      <td>4.409722</td>\n",
       "      <td>9.280556</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.888194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GRE Score  TOEFL Score       SOP       LOR      CGPA  \\\n",
       "University Rating                                                          \n",
       "1.000000           304.156250    99.968750  1.937500  2.406250  7.786875   \n",
       "2.000000           309.548387   103.685484  2.689516  2.955645  8.186452   \n",
       "3.000000           315.032468   106.292208  3.321429  3.405844  8.504545   \n",
       "3.121649           315.133333   105.600000  3.133333  3.266667  8.346667   \n",
       "4.000000           323.213592   111.087379  3.990291  3.956311  8.940000   \n",
       "5.000000           327.236111   113.486111  4.472222  4.409722  9.280556   \n",
       "\n",
       "                   Research  Chance of Admit  \n",
       "University Rating                             \n",
       "1.000000           0.281250         0.560937  \n",
       "2.000000           0.298387         0.627339  \n",
       "3.000000           0.538961         0.703701  \n",
       "3.121649           0.466667         0.683333  \n",
       "4.000000           0.786408         0.801553  \n",
       "5.000000           0.875000         0.888194  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_university = df.groupby(by='University Rating').mean()\n",
    "df_university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Chance of Admit'],axis=1)\n",
    "y=df['Chance of Admit']\n",
    "# here we are droping the Chance of Admit and serial no, as they are not going to be used for the features \n",
    "# Chance of Admit is the target column which shows the probalility of admission for a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  Research\n",
       "0      337.0        118.0                4.0  4.5  4.5  9.65         1\n",
       "1      324.0        107.0                4.0  4.0  4.5  8.87         1\n",
       "2      312.0        104.0                3.0  3.0  3.5  8.00         1\n",
       "3      322.0        110.0                3.0  3.5  2.5  8.67         1\n",
       "4      314.0        103.0                2.0  2.0  3.0  8.21         0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head() # checking the transformed feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.85052822,  1.77547686,  0.77890565, ...,  1.09894429,\n",
       "         1.77680627,  0.88640526],\n",
       "       [ 0.68147064, -0.04027672,  0.77890565, ...,  1.09894429,\n",
       "         0.48585943,  0.88640526],\n",
       "       [-0.39765943, -0.53548224, -0.1078766 , ...,  0.01730621,\n",
       "        -0.95404281,  0.88640526],\n",
       "       ...,\n",
       "       [ 1.22103568,  2.10561387,  1.66568791, ...,  1.63976333,\n",
       "         1.62785086,  0.88640526],\n",
       "       [-0.39765943, -0.70055074,  0.77890565, ...,  1.63976333,\n",
       "        -0.24236699, -1.12815215],\n",
       "       [ 0.95125316,  0.95013432,  0.77890565, ...,  1.09894429,\n",
       "         0.76721964, -1.12815215]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be only used if you want to scale the data,standize the data,if the variation is huge in the dataset\n",
    "# when we have huge variation in the data set\n",
    "# i am not changing the data , i am changing the scale only like taking logs, sqrt--not changing the actual meaning of the data set\n",
    "# variance betweeen the dataset become very low\n",
    "# machine will understand in better way this data  as having low variance in the data set\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_feature=StandardScaler()\n",
    "scaler_lablel=StandardScaler()\n",
    "scaled_data=scaler_feature.fit_transform(x)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.33,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076993525686699"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting accuracy almost 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.20,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149558487897137"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#tf.keras.layers.Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 50)                400       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 150)               7650      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,301\n",
      "Trainable params: 38,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN_model = keras.Sequential()\n",
    "ANN_model.add(Dense(50, input_dim = 7))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(50))\n",
    "ANN_model.add(Activation('linear'))\n",
    "ANN_model.add(Dense(1))\n",
    "ANN_model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 9ms/step - loss: 864.7169 - val_loss: 2.9432\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 130.2803 - val_loss: 1.8248\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 61.8394 - val_loss: 1.7636\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38.5290 - val_loss: 1.1356\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26.6716 - val_loss: 1.0885\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 18.1976 - val_loss: 1.6986\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.5961 - val_loss: 1.0864\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11.0469 - val_loss: 1.1715\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.6027 - val_loss: 1.0900\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.8417 - val_loss: 1.0769\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.5748 - val_loss: 1.0641\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.2735 - val_loss: 1.0690\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.5639 - val_loss: 1.0572\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.0535 - val_loss: 1.1189\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.4024 - val_loss: 1.0567\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.3084 - val_loss: 1.0878\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.4733 - val_loss: 1.0648\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.4824 - val_loss: 1.0848\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.4829 - val_loss: 1.1032\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.4839 - val_loss: 1.0491\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.0252 - val_loss: 1.0330\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.3097 - val_loss: 1.0732\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1930 - val_loss: 1.0334\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.2121 - val_loss: 1.0708\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1086 - val_loss: 1.0560\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.8963 - val_loss: 1.0710\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.8935 - val_loss: 1.0613\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.6776 - val_loss: 1.0301\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7698 - val_loss: 1.0253\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.5700 - val_loss: 1.0421\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6939 - val_loss: 1.0253\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4587 - val_loss: 1.0899\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6073 - val_loss: 1.0264\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6343 - val_loss: 1.0833\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4926 - val_loss: 1.0640\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4164 - val_loss: 1.0358\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4454 - val_loss: 1.0596\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3223 - val_loss: 1.0239\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4951 - val_loss: 1.0733\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3116 - val_loss: 1.0332\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3836 - val_loss: 1.0526\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4684 - val_loss: 1.0866\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2271 - val_loss: 1.0372\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4295 - val_loss: 1.0407\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3081 - val_loss: 1.0488\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3182 - val_loss: 1.1010\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2123 - val_loss: 1.0319\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3551 - val_loss: 1.0294\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2917 - val_loss: 1.1177\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2045 - val_loss: 1.0286\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2859 - val_loss: 1.0643\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3200 - val_loss: 1.1004\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1740 - val_loss: 1.0625\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1579 - val_loss: 1.0285\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2254 - val_loss: 1.0296\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1894 - val_loss: 1.0332\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2651 - val_loss: 1.0382\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1524 - val_loss: 1.0427\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0604 - val_loss: 1.0377\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1133 - val_loss: 1.0443\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2590 - val_loss: 1.0334\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1429 - val_loss: 1.0261\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2226 - val_loss: 1.0478\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1739 - val_loss: 1.0537\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1909 - val_loss: 1.0287\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1513 - val_loss: 1.0476\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2546 - val_loss: 1.0619\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0831 - val_loss: 1.0298\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2378 - val_loss: 1.1272\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2208 - val_loss: 1.0154\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2190 - val_loss: 1.0316\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1856 - val_loss: 1.0544\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1642 - val_loss: 1.0324\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1135 - val_loss: 1.0219\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1609 - val_loss: 1.0377\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1137 - val_loss: 1.0219\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1355 - val_loss: 1.0218\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1292 - val_loss: 1.0199\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1940 - val_loss: 1.0458\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2138 - val_loss: 1.0381\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1437 - val_loss: 1.0565\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1319 - val_loss: 1.0261\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0807 - val_loss: 1.0556\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1056 - val_loss: 1.0605\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1987 - val_loss: 1.0323\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0974 - val_loss: 1.0435\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0944 - val_loss: 1.0796\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1842 - val_loss: 1.0231\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1498 - val_loss: 1.0393\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1690 - val_loss: 1.1016\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1704 - val_loss: 1.0181\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1610 - val_loss: 1.0217\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1404 - val_loss: 1.0278\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1245 - val_loss: 1.0286\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1213 - val_loss: 1.0139\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0704 - val_loss: 1.0191\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0709 - val_loss: 1.0247\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0421 - val_loss: 1.0230\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1226 - val_loss: 1.0226\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1365 - val_loss: 1.0201\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = ANN_model.fit(train_x, train_y, epochs = 100, batch_size = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0609\n",
      "Accuracy : -0.06088292598724365\n"
     ]
    }
   ],
   "source": [
    "result = ANN_model.evaluate(test_x, test_y)\n",
    "accuracy_ANN = 1 - result\n",
    "print(\"Accuracy : {}\".format(accuracy_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17c246b3a90>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend(['Training Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN AND EVALUATE A DECISION TREE AND RANDOM FOREST MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree builds regression or classification models in the form of a tree structure. \n",
    "# Decision tree breaks down a dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "# The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree_model = DecisionTreeRegressor()\n",
    "decisionTree_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6396309945204307"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decisionTree = decisionTree_model.score(test_x, test_y)\n",
    "accuracy_decisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many decision Trees make up a random forest model which is an ensemble model. \n",
    "# Predictions made by each decision tree are averaged to get the prediction of random forest model.\n",
    "# A random forest regressor fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhus\\AppData\\Local\\Temp/ipykernel_7664/2085754441.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_model.fit(train_x, train_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7942773123164613"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForest_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "randomForest_model.fit(train_x, train_y)\n",
    "accuracy_randomforest = randomForest_model.score(test_x, test_y)\n",
    "accuracy_randomforest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNDERSTAND VARIOUS REGRESSION KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17c26ff9e50>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = reg.predict(test_x)\n",
    "plt.plot(test_y, y_pred, '^', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_orig = scaler_y.inverse_transform(y_pred)\n",
    "y_test_orig = scaler_y.inverse_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = test_x.shape[1]\n",
    "n = len(test_x)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.058 \n",
      "MSE = 0.0033200058289450845 \n",
      "MAE = 0.044688261926697725 \n",
      "R2 = 0.8287147890102629 \n",
      "Adjusted R2 = 0.8156822186088698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))\n",
    "MSE = mean_squared_error(y_test_orig, y_predict_orig)\n",
    "MAE = mean_absolute_error(y_test_orig, y_predict_orig)\n",
    "r2 = r2_score(y_test_orig, y_predict_orig)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the model to the local file system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pickle library- used to convert object into bytecode - called serialization\n",
    "- deserialization- converting bytecode to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename='finalized_model.pickle'\n",
    "#pickle.dump(reg,open(filename,'wb'))\n",
    "dump(reg, 'filename.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n",
      "(1, 7)\n"
     ]
    }
   ],
   "source": [
    "s = np.array([340, 120, 5, 5, 5, 9.6, 1])\n",
    "print(s.shape)\n",
    "s = s.reshape(1,-1)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = pickle.load(open(filename, 'rb'))\n",
    "#print(model.predict(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model=pickle.load(open(filename,'rb'))\n",
    "#a=loaded_model.predict([[300,110,5,5,5,10,1]])\n",
    "#a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=loaded_model.predict([[320,120,5,5,5,10,1]])\n",
    "#a[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
