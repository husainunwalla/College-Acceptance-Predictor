{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- ### The goal here is to find the chance of admission of a candidate based on his/her GRE score, TOEFL score, rating of the university in which he/she is trying to get admission,strength of the SOP,Strength of the letter of the recommendation, CGPA and the research experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Prediction.csv\")  # importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.', axis=1, inplace=True)\n",
    "df.drop('SOP', axis=1, inplace=True)\n",
    "df.drop('LOR', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRE Score'].fillna(df['GRE Score'].mode()[0],inplace=True)\n",
    "df['TOEFL Score'].fillna(df['TOEFL Score'].mode()[0],inplace=True)\n",
    "df['University Rating'].fillna(df['University Rating'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4.3</th>\n",
       "      <td>316.857143</td>\n",
       "      <td>105.857143</td>\n",
       "      <td>8.434286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.5</th>\n",
       "      <td>317.833333</td>\n",
       "      <td>104.833333</td>\n",
       "      <td>8.973333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.9</th>\n",
       "      <td>314.692308</td>\n",
       "      <td>95.538462</td>\n",
       "      <td>8.346154</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.6</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>7.683333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.4</th>\n",
       "      <td>306.285714</td>\n",
       "      <td>99.571429</td>\n",
       "      <td>6.808571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.6</th>\n",
       "      <td>307.750000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>302.750000</td>\n",
       "      <td>100.625000</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.4</th>\n",
       "      <td>310.500000</td>\n",
       "      <td>105.666667</td>\n",
       "      <td>8.076667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.1</th>\n",
       "      <td>296.285714</td>\n",
       "      <td>97.428571</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.9</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>99.166667</td>\n",
       "      <td>7.318333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.6</th>\n",
       "      <td>313.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.8</th>\n",
       "      <td>288.666667</td>\n",
       "      <td>96.066667</td>\n",
       "      <td>7.646000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67.0</th>\n",
       "      <td>264.428571</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.884286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68.5</th>\n",
       "      <td>300.666667</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>8.040000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.7</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>100.833333</td>\n",
       "      <td>6.776667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>301.285714</td>\n",
       "      <td>100.571429</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.1</th>\n",
       "      <td>215.857143</td>\n",
       "      <td>90.428571</td>\n",
       "      <td>7.688571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82.3</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.0</th>\n",
       "      <td>293.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GRE Score  TOEFL Score      CGPA  Research  \\\n",
       "University Rating                                                \n",
       "4.3                316.857143   105.857143  8.434286  0.714286   \n",
       "15.0               317.000000   110.000000  8.880000  0.000000   \n",
       "16.0               317.000000   110.000000  8.880000  0.000000   \n",
       "17.5               317.833333   104.833333  8.973333  0.666667   \n",
       "20.0               317.000000   110.000000  8.880000  0.000000   \n",
       "29.9               314.692308    95.538462  8.346154  0.461538   \n",
       "36.6               316.000000   107.833333  7.683333  0.333333   \n",
       "38.4               306.285714    99.571429  6.808571  0.428571   \n",
       "39.6               307.750000   103.750000  8.490000  0.500000   \n",
       "42.0               302.750000   100.625000  8.218750  0.750000   \n",
       "46.4               310.500000   105.666667  8.076667  0.500000   \n",
       "47.0               317.000000   110.000000  8.880000  0.000000   \n",
       "50.1               296.285714    97.428571  7.370000  0.571429   \n",
       "55.9               296.000000    99.166667  7.318333  0.333333   \n",
       "63.6               313.000000   104.000000  7.950000  0.500000   \n",
       "65.8               288.666667    96.066667  7.646000  0.533333   \n",
       "67.0               264.428571   104.000000  7.884286  0.571429   \n",
       "68.5               300.666667    98.666667  8.040000  0.500000   \n",
       "70.7               303.000000   100.833333  6.776667  0.500000   \n",
       "71.0               301.285714   100.571429  7.160000  0.428571   \n",
       "80.1               215.857143    90.428571  7.688571  0.571429   \n",
       "82.3               292.000000    87.000000  7.900000  0.000000   \n",
       "99.0               293.000000    92.000000  6.000000  0.000000   \n",
       "\n",
       "                   Chance of Admit  \n",
       "University Rating                   \n",
       "4.3                       0.428571  \n",
       "15.0                      0.000000  \n",
       "16.0                      0.000000  \n",
       "17.5                      0.500000  \n",
       "20.0                      1.000000  \n",
       "29.9                      0.461538  \n",
       "36.6                      0.500000  \n",
       "38.4                      0.285714  \n",
       "39.6                      0.750000  \n",
       "42.0                      0.500000  \n",
       "46.4                      0.500000  \n",
       "47.0                      1.000000  \n",
       "50.1                      0.571429  \n",
       "55.9                      0.500000  \n",
       "63.6                      0.250000  \n",
       "65.8                      0.466667  \n",
       "67.0                      0.571429  \n",
       "68.5                      0.500000  \n",
       "70.7                      0.500000  \n",
       "71.0                      0.571429  \n",
       "80.1                      0.571429  \n",
       "82.3                      0.333333  \n",
       "99.0                      1.000000  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_university = df.groupby(by='University Rating').mean()\n",
    "df_university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Chance of Admit'],axis=1)\n",
    "y=df['Chance of Admit']\n",
    "# here we are droping the Chance of Admit and serial no, as they are not going to be used for the features \n",
    "# Chance of Admit is the target column which shows the probalility of admission for a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  CGPA  Research\n",
       "0        317          110               47.0  8.88         0\n",
       "1        317          110               16.0  8.88         0\n",
       "2        317          110                4.3  8.88         0\n",
       "3        317          110               20.0  8.88         0\n",
       "4        317          110               15.0  8.88         0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head() # checking the transformed feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.50595114e-01,  6.56243559e-01, -1.47630258e-01,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.60476947e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -2.15472202e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.41675151e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.65177396e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [-9.11887131e-02, -5.24086900e-01,  2.29660326e+00,\n",
       "        -1.91521827e+00, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -6.55234729e-01,  1.51162827e+00,\n",
       "        -3.49644752e-01, -9.84731928e-01],\n",
       "       [ 1.92572438e-02, -6.55234729e-01,  1.51162827e+00,\n",
       "         5.89699359e-01, -9.84731928e-01],\n",
       "       [-2.01634670e-01, -1.24539996e+00,  1.51162827e+00,\n",
       "        -3.65300488e-02, -9.84731928e-01],\n",
       "       [ 5.53079369e-01,  6.56243559e-01,  6.32644289e-01,\n",
       "        -7.82786759e-02, -9.84731928e-01],\n",
       "       [ 2.76964476e-01,  5.04414726e-04,  6.32644289e-01,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 5.60725627e-02, -2.61791243e-01,  6.32644289e-01,\n",
       "         5.79262202e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  6.56243559e-01,  6.32644289e-01,\n",
       "         1.56557352e-02, -9.84731928e-01],\n",
       "       [ 6.26710006e-01,  6.56243559e-01, -2.15472202e+00,\n",
       "         9.44562689e-01,  1.01550480e+00],\n",
       "       [ 6.45117666e-01,  8.52965302e-01, -2.15472202e+00,\n",
       "         1.68560082e+00,  1.01550480e+00],\n",
       "       [ 7.37155963e-01,  1.18083487e+00, -2.15472202e+00,\n",
       "         1.30986318e+00,  1.01550480e+00],\n",
       "       [ 3.76649032e-02, -6.55234729e-01, -2.15472202e+00,\n",
       "         3.80956223e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02,  5.04414726e-04, -2.15472202e+00,\n",
       "        -5.16639261e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04,  5.04414726e-04, -2.15472202e+00,\n",
       "        -5.16639261e-01, -9.84731928e-01],\n",
       "       [ 4.97856390e-01,  5.04414726e-04,  9.66376173e-01,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 5.60725627e-02,  5.04414726e-04,  9.66376173e-01,\n",
       "        -9.13251219e-01,  1.01550480e+00],\n",
       "       [-7.27810536e-02,  3.28373987e-01,  9.66376173e-01,\n",
       "        -5.27076418e-01,  1.01550480e+00],\n",
       "       [-5.43733941e-02, -3.27365157e-01,  9.66376173e-01,\n",
       "        -2.88587385e+00, -9.84731928e-01],\n",
       "       [ 3.76649032e-02,  6.56243559e-01,  9.66376173e-01,\n",
       "        -2.54144768e+00, -9.84731928e-01],\n",
       "       [ 9.28878817e-02, -3.27365157e-01,  9.66376173e-01,\n",
       "        -6.62759456e-01,  1.01550480e+00],\n",
       "       [ 6.81932985e-01,  9.84113131e-01, -1.53426274e+00,\n",
       "         2.07177562e+00,  1.01550480e+00],\n",
       "       [ 4.97856390e-01,  6.56243559e-01, -1.53426274e+00,\n",
       "         2.17614719e+00,  1.01550480e+00],\n",
       "       [ 5.34671709e-01,  5.25095730e-01, -1.53426274e+00,\n",
       "         1.63341504e+00,  1.01550480e+00],\n",
       "       [ 1.66518520e-01, -3.92939072e-01, -1.53426274e+00,\n",
       "        -5.58387888e-01,  1.01550480e+00],\n",
       "       [ 2.76964476e-01,  4.59521815e-01, -1.53426274e+00,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02, -3.27365157e-01, -1.53426274e+00,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 4.05818093e-01,  7.87391387e-01, -6.36476963e-01,\n",
       "        -1.40901617e-01,  1.01550480e+00],\n",
       "       [ 4.42633412e-01,  4.59521815e-01, -6.36476963e-01,\n",
       "        -4.54016320e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  1.18083487e+00, -6.36476963e-01,\n",
       "         1.06980857e+00, -9.84731928e-01],\n",
       "       [ 2.95372136e-01,  7.87391387e-01, -6.36476963e-01,\n",
       "        -1.58122925e+00, -9.84731928e-01],\n",
       "       [ 2.40149157e-01,  4.59521815e-01, -6.36476963e-01,\n",
       "        -5.37513575e-01, -9.84731928e-01],\n",
       "       [ 1.84926179e-01, -5.89660815e-01, -6.36476963e-01,\n",
       "         6.94070926e-01, -9.84731928e-01],\n",
       "       [ 3.87410433e-01,  1.04968705e+00, -9.51407051e-01,\n",
       "         1.81084670e+00, -9.84731928e-01],\n",
       "       [ 3.87410433e-01,  1.24640879e+00, -9.51407051e-01,\n",
       "         1.12199435e+00,  1.01550480e+00],\n",
       "       [ 5.16264050e-01,  3.28373987e-01, -9.51407051e-01,\n",
       "         1.14286867e+00, -9.84731928e-01],\n",
       "       [ 1.29703201e-01, -9.83104301e-01, -9.51407051e-01,\n",
       "         7.98442494e-01, -9.84731928e-01],\n",
       "       [ 4.79448731e-01,  3.28373987e-01, -9.51407051e-01,\n",
       "        -4.54016320e-01, -9.84731928e-01],\n",
       "       [ 1.92572438e-02,  3.93947901e-01, -9.51407051e-01,\n",
       "        -2.87021812e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  5.25095730e-01, -1.75832953e-01,\n",
       "         9.91529895e-02,  1.01550480e+00],\n",
       "       [ 3.69002774e-01,  6.56243559e-01, -1.75832953e-01,\n",
       "         4.33142007e-01, -9.84731928e-01],\n",
       "       [ 3.32187455e-01,  6.56243559e-01, -1.75832953e-01,\n",
       "         1.32030033e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  1.31652244e-01, -1.75832953e-01,\n",
       "        -8.71502592e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02,  3.28373987e-01, -1.75832953e-01,\n",
       "        -1.40901617e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04, -6.50694997e-02, -1.75832953e-01,\n",
       "         6.73196613e-01,  1.01550480e+00],\n",
       "       [ 1.84926179e-01,  6.56243559e-01, -3.82652712e-01,\n",
       "         1.23680308e+00,  1.01550480e+00],\n",
       "       [-2.93672967e-01,  3.28373987e-01, -3.82652712e-01,\n",
       "        -3.80956223e-01,  1.01550480e+00],\n",
       "       [ 7.44802222e-02,  3.28373987e-01, -3.82652712e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [ 2.95372136e-01,  7.21817473e-01, -3.82652712e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01,  1.31652244e-01, -3.82652712e-01,\n",
       "         2.76584655e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01, -3.27365157e-01, -3.82652712e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [-3.59657347e-02, -1.17982604e+00, -3.82652712e-01,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -3.27365157e-01, -3.82652712e-01,\n",
       "        -2.87021812e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02,  5.04414726e-04, -1.91633693e-03,\n",
       "        -7.77568181e-01,  1.01550480e+00],\n",
       "       [ 5.60725627e-02, -3.92939072e-01, -1.91633693e-03,\n",
       "        -3.65300488e-02, -9.84731928e-01],\n",
       "       [-1.83227010e-01,  5.04414726e-04, -1.91633693e-03,\n",
       "        -2.87021812e-01, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -3.27365157e-01, -1.91633693e-03,\n",
       "        -1.08024573e+00,  1.01550480e+00],\n",
       "       [ 3.13779795e-01,  3.28373987e-01,  2.70709710e-01,\n",
       "         6.78415191e-02, -9.84731928e-01],\n",
       "       [-1.75580752e-02, -3.27365157e-01,  2.70709710e-01,\n",
       "        -3.49644752e-01,  1.01550480e+00],\n",
       "       [-1.09596373e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [-1.64819351e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "        -9.75874160e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -3.27365157e-01,  2.70709710e-01,\n",
       "        -1.18461730e+00, -9.84731928e-01],\n",
       "       [-2.38449989e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "        -1.06980857e+00, -9.84731928e-01],\n",
       "       [ 2.03333838e-01,  5.04414726e-04,  8.62966294e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [ 1.66518520e-01, -1.30643414e-01,  8.62966294e-01,\n",
       "         7.98442494e-01, -9.84731928e-01],\n",
       "       [ 4.24225752e-01,  5.25095730e-01,  8.62966294e-01,\n",
       "         4.85327791e-01,  1.01550480e+00],\n",
       "       [-2.93672967e-01, -3.27365157e-01,  8.62966294e-01,\n",
       "        -8.71502592e-01,  1.01550480e+00],\n",
       "       [-5.43733941e-02, -3.27365157e-01,  8.62966294e-01,\n",
       "         4.33142007e-01, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -2.61791243e-01,  8.62966294e-01,\n",
       "         1.61775930e-01, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  5.04414726e-04, -9.51407051e-01,\n",
       "         3.07896125e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  5.04414726e-04, -9.51407051e-01,\n",
       "        -5.74043623e-02,  1.01550480e+00],\n",
       "       [ 3.87410433e-01,  4.59521815e-01, -9.51407051e-01,\n",
       "         6.10573672e-01, -9.84731928e-01],\n",
       "       [ 1.29703201e-01, -9.83104301e-01, -9.51407051e-01,\n",
       "         1.21592877e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  5.25095730e-01, -9.51407051e-01,\n",
       "        -5.58387888e-01,  1.01550480e+00],\n",
       "       [ 3.13779795e-01, -6.55688702e+00, -9.51407051e-01,\n",
       "         1.52904347e+00, -9.84731928e-01],\n",
       "       [ 2.58556817e-01,  3.93947901e-01, -9.51407051e-01,\n",
       "        -2.45273185e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01, -2.61791243e-01, -5.51868879e-01,\n",
       "        -1.09590146e-01, -9.84731928e-01],\n",
       "       [ 4.05818093e-01,  7.21817473e-01, -5.51868879e-01,\n",
       "        -1.08024573e+00,  1.01550480e+00],\n",
       "       [ 1.48110860e-01, -1.30643414e-01, -5.51868879e-01,\n",
       "         6.78415191e-02, -9.84731928e-01],\n",
       "       [-7.27810536e-02, -9.83104301e-01, -5.51868879e-01,\n",
       "        -1.39336043e+00,  1.01550480e+00],\n",
       "       [ 2.03333838e-01,  5.25095730e-01, -5.51868879e-01,\n",
       "        -1.57079210e+00,  1.01550480e+00],\n",
       "       [-7.27810536e-02, -6.50694997e-02, -5.51868879e-01,\n",
       "        -8.71502592e-01, -9.84731928e-01],\n",
       "       [ 2.03333838e-01,  5.04414726e-04, -5.51868879e-01,\n",
       "        -2.54144768e+00, -9.84731928e-01],\n",
       "       [-1.83227010e-01, -1.30643414e-01, -1.91633693e-03,\n",
       "        -2.87021812e-01, -9.84731928e-01],\n",
       "       [-1.75580752e-02, -1.30643414e-01, -1.91633693e-03,\n",
       "         1.40901617e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01, -1.96217328e-01, -1.91633693e-03,\n",
       "        -1.06980857e+00,  1.01550480e+00],\n",
       "       [ 7.44802222e-02, -1.30643414e-01,  7.36054169e-01,\n",
       "         1.80040955e+00, -9.84731928e-01],\n",
       "       [ 2.58556817e-01,  3.28373987e-01,  7.36054169e-01,\n",
       "         1.72213087e-01, -9.84731928e-01],\n",
       "       [ 3.32187455e-01,  5.90669644e-01,  7.36054169e-01,\n",
       "        -4.74890634e-01, -9.84731928e-01],\n",
       "       [ 1.66518520e-01,  3.28373987e-01,  7.36054169e-01,\n",
       "         2.97458968e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  1.31652244e-01,  7.36054169e-01,\n",
       "        -1.35161180e+00, -9.84731928e-01],\n",
       "       [ 1.48110860e-01,  7.87391387e-01,  7.36054169e-01,\n",
       "        -5.27076418e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04,  3.28373987e-01,  7.36054169e-01,\n",
       "         1.72213087e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01,  7.87391387e-01,  7.36054169e-01,\n",
       "        -1.46642053e+00,  1.01550480e+00],\n",
       "       [ 2.03333838e-01,  3.28373987e-01,  1.40821839e+00,\n",
       "        -3.49644752e-01,  1.01550480e+00],\n",
       "       [ 7.44802222e-02, -9.83104301e-01,  1.40821839e+00,\n",
       "         8.08879651e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -7.86382558e-01,  1.40821839e+00,\n",
       "         9.86311317e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02, -9.83104301e-01,  1.40821839e+00,\n",
       "        -2.60928920e-02,  1.01550480e+00],\n",
       "       [ 7.44802222e-02,  1.31652244e-01,  1.40821839e+00,\n",
       "        -2.20745866e+00, -9.84731928e-01],\n",
       "       [-5.48463294e+00, -1.96671302e+00,  1.40821839e+00,\n",
       "        -2.45273185e-01, -9.84731928e-01],\n",
       "       [-5.48463294e+00, -1.30643414e-01,  1.40821839e+00,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 3.32187455e-01, -6.55688702e+00,  7.36054169e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  6.56243559e-01,  7.36054169e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 4.05818093e-01, -9.83104301e-01,  7.36054169e-01,\n",
       "        -2.45273185e-01,  1.01550480e+00],\n",
       "       [ 1.84926179e-01, -9.83104301e-01,  7.36054169e-01,\n",
       "        -4.54016320e-01, -9.84731928e-01],\n",
       "       [-5.48463294e+00,  3.28373987e-01,  7.36054169e-01,\n",
       "        -7.04508083e-01,  1.01550480e+00],\n",
       "       [ 9.28878817e-02,  2.62800072e-01,  7.36054169e-01,\n",
       "        -1.17418014e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  2.62800072e-01,  7.36054169e-01,\n",
       "        -8.08879651e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  3.28373987e-01,  9.80477521e-01,\n",
       "        -1.28898886e+00,  1.01550480e+00],\n",
       "       [ 1.92572438e-02,  7.21817473e-01,  9.80477521e-01,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 4.42633412e-01, -5.24086900e-01,  9.80477521e-01,\n",
       "         6.62759456e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02, -1.30643414e-01,  9.80477521e-01,\n",
       "        -6.41885143e-01, -9.84731928e-01],\n",
       "       [-1.64819351e-01, -1.30643414e-01,  9.80477521e-01,\n",
       "        -1.46642053e+00, -9.84731928e-01],\n",
       "       [-3.48895946e-01,  3.28373987e-01,  9.80477521e-01,\n",
       "        -8.61065435e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01, -3.27365157e-01,  9.80477521e-01,\n",
       "        -1.29942602e+00, -9.84731928e-01],\n",
       "       [ 2.95372136e-01,  9.84113131e-01,  7.92459558e-01,\n",
       "         7.35819554e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01, -6.50694997e-02,  7.92459558e-01,\n",
       "         1.51860631e+00,  1.01550480e+00],\n",
       "       [ 2.95372136e-01,  7.21817473e-01,  7.92459558e-01,\n",
       "         1.41423474e+00, -9.84731928e-01],\n",
       "       [ 9.28878817e-02, -7.20808644e-01,  7.92459558e-01,\n",
       "        -5.79262202e-01,  1.01550480e+00],\n",
       "       [ 1.48110860e-01,  3.28373987e-01,  7.92459558e-01,\n",
       "        -7.98442494e-01,  1.01550480e+00],\n",
       "       [-5.48463294e+00,  3.28373987e-01,  7.92459558e-01,\n",
       "        -1.56557352e-02,  1.01550480e+00],\n",
       "       [ 1.11295541e-01,  2.62800072e-01,  7.92459558e-01,\n",
       "        -1.91521827e+00, -9.84731928e-01],\n",
       "       [ 1.11295541e-01,  1.97226158e-01, -4.95463490e-01,\n",
       "         9.23688376e-01,  1.01550480e+00],\n",
       "       [ 4.05818093e-01,  1.18083487e+00, -4.95463490e-01,\n",
       "         1.29942602e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  6.60783291e-02, -4.95463490e-01,\n",
       "         1.72213087e-01,  1.01550480e+00],\n",
       "       [-1.75580752e-02, -4.58512986e-01, -4.95463490e-01,\n",
       "         3.39207596e-01, -9.84731928e-01]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be only used if you want to scale the data,standize the data,if the variation is huge in the dataset\n",
    "# when we have huge variation in the data set\n",
    "# i am not changing the data , i am changing the scale only like taking logs, sqrt--not changing the actual meaning of the data set\n",
    "# variance betweeen the dataset become very low\n",
    "# machine will understand in better way this data  as having low variance in the data set\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_feature=StandardScaler()\n",
    "scaler_lablel=StandardScaler()\n",
    "scaled_data=scaler_feature.fit_transform(x)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.33,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7868583905683451"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.004019\n",
      "TOEFL Score           0.016411\n",
      "University Rating     0.018374\n",
      "CGPA                  0.555673\n",
      "Research              0.501356\n",
      "Feature: 0, Score: 0.00402\n",
      "Feature: 1, Score: 0.01641\n",
      "Feature: 2, Score: 0.01837\n",
      "Feature: 3, Score: 0.55567\n",
      "Feature: 4, Score: 0.50136\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "intercept = reg.intercept_\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = reg.coef_[0]\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.20,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3061374667932135"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#tf.keras.layers.Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 50)                300       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 150)               7650      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,201\n",
      "Trainable params: 38,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN_model = keras.Sequential()\n",
    "ANN_model.add(Dense(50, input_dim = 5))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(50))\n",
    "ANN_model.add(Activation('linear'))\n",
    "ANN_model.add(Dense(1))\n",
    "ANN_model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1750.2340 - val_loss: 5.8305\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1630.5289 - val_loss: 37.0596\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1169.6068 - val_loss: 16.0213\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 513.9368 - val_loss: 15.5094\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 366.6048 - val_loss: 5.1717\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 270.6135 - val_loss: 3.9914\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 220.4196 - val_loss: 2.7003\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 196.9081 - val_loss: 2.8743\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 181.0622 - val_loss: 2.7795\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 109.4225 - val_loss: 1.6123\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 140.3224 - val_loss: 1.7694\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 101.7322 - val_loss: 1.4960\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 73.4092 - val_loss: 1.1525\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 80.4110 - val_loss: 1.3926\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.1810 - val_loss: 1.9516\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 56.9267 - val_loss: 2.3264\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 71.6391 - val_loss: 1.7108\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.8422 - val_loss: 1.6257\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 42.8622 - val_loss: 1.4480\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 40.0113 - val_loss: 1.5162\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 32.4419 - val_loss: 2.0549\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.0163 - val_loss: 1.5884\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.9731 - val_loss: 1.4564\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.5821 - val_loss: 1.9078\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.8204 - val_loss: 1.5679\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.0247 - val_loss: 1.4132\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 31.5372 - val_loss: 1.4320\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.5664 - val_loss: 1.3893\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 17.6306 - val_loss: 1.3926\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 16.0348 - val_loss: 1.3667\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.7206 - val_loss: 1.3342\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.6312 - val_loss: 1.3606\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.5192 - val_loss: 1.3406\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.7577 - val_loss: 1.3119\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.6521 - val_loss: 1.2786\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.5000 - val_loss: 1.2655\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 15.8705 - val_loss: 1.3416\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.7496 - val_loss: 1.4385\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.2081 - val_loss: 1.2671\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.0735 - val_loss: 1.1321\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.0415 - val_loss: 1.1057\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.8378 - val_loss: 1.0832\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.1240 - val_loss: 1.0926\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.1690 - val_loss: 1.1227\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.6239 - val_loss: 1.1083\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.4469 - val_loss: 1.1265\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 11.6263 - val_loss: 1.1315\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7940 - val_loss: 1.1941\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.9635 - val_loss: 1.0893\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.8163 - val_loss: 1.0720\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6225 - val_loss: 1.0722\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2747 - val_loss: 1.0402\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6380 - val_loss: 1.0275\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.4381 - val_loss: 1.0557\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9281 - val_loss: 1.0576\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1287 - val_loss: 1.0457\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1676 - val_loss: 0.9855\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7848 - val_loss: 1.0131\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3766 - val_loss: 1.1352\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.5347 - val_loss: 0.9856\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3786 - val_loss: 0.9782\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1371 - val_loss: 1.0167\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0265 - val_loss: 0.9847\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5584 - val_loss: 0.9485\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3902 - val_loss: 0.9433\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0942 - val_loss: 0.9402\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1378 - val_loss: 0.9383\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5167 - val_loss: 0.9427\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9638 - val_loss: 0.9407\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0264 - val_loss: 0.9371\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5900 - val_loss: 0.9393\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3303 - val_loss: 0.9605\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6313 - val_loss: 0.9518\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6402 - val_loss: 0.9538\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.9933 - val_loss: 0.9902\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6807 - val_loss: 0.9706\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5072 - val_loss: 0.9459\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7025 - val_loss: 0.9460\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9067 - val_loss: 0.9585\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2888 - val_loss: 0.9637\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.1057 - val_loss: 0.9545\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1253 - val_loss: 0.9559\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.2706 - val_loss: 0.9867\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5929 - val_loss: 0.9804\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5256 - val_loss: 0.9553\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0183 - val_loss: 0.9539\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4633 - val_loss: 0.9597\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.5825 - val_loss: 0.9757\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1027 - val_loss: 0.9581\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3073 - val_loss: 0.9575\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4870 - val_loss: 0.9550\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1058 - val_loss: 0.9543\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3533 - val_loss: 0.9701\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9717 - val_loss: 0.9604\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2042 - val_loss: 0.9546\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8065 - val_loss: 0.9561\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2894 - val_loss: 0.9560\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7144 - val_loss: 0.9679\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7304 - val_loss: 0.9770\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8859 - val_loss: 0.9753\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = ANN_model.fit(train_x, train_y, epochs = 100, batch_size = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9522\n",
      "Accuracy : 0.04775357246398926\n"
     ]
    }
   ],
   "source": [
    "result = ANN_model.evaluate(test_x, test_y)\n",
    "accuracy_ANN = 1 - result\n",
    "print(\"Accuracy : {}\".format(accuracy_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17f87182df0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend(['Training Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decesion Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree builds regression or classification models in the form of a tree structure. \n",
    "# Decision tree breaks down a dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "# The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree_model = DecisionTreeRegressor()\n",
    "decisionTree_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.332001\n",
      "TOEFL Score           0.037783\n",
      "University Rating     0.296915\n",
      "CGPA                  0.231926\n",
      "Research              0.101375\n",
      "Feature: 0, Score: 0.33200\n",
      "Feature: 1, Score: 0.03778\n",
      "Feature: 2, Score: 0.29691\n",
      "Feature: 3, Score: 0.23193\n",
      "Feature: 4, Score: 0.10138\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = decisionTree_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05454545454545445"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decisionTree = decisionTree_model.score(test_x, test_y)\n",
    "accuracy_decisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhus\\AppData\\Local\\Temp/ipykernel_16464/2085754441.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_model.fit(train_x, train_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4085236363636361"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForest_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "randomForest_model.fit(train_x, train_y)\n",
    "accuracy_randomforest = randomForest_model.score(test_x, test_y)\n",
    "accuracy_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.339245\n",
      "TOEFL Score           0.127996\n",
      "University Rating     0.223136\n",
      "CGPA                  0.256137\n",
      "Research              0.053487\n",
      "Feature: 0, Score: 0.33924\n",
      "Feature: 1, Score: 0.12800\n",
      "Feature: 2, Score: 0.22314\n",
      "Feature: 3, Score: 0.25614\n",
      "Feature: 4, Score: 0.05349\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = randomForest_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model to the local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename='finalized_model.pickle'\n",
    "#pickle.dump(reg,open(filename,'wb'))\n",
    "dump(randomForest_model, 'filename.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
