{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- ### The goal here is to find the chance of admission of a candidate based on his/her GRE score, TOEFL score, rating of the university in which he/she is trying to get admission,strength of the SOP,Strength of the letter of the recommendation, CGPA and the research experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Prediction.csv\")  # importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.', axis=1, inplace=True)\n",
    "df.drop('SOP', axis=1, inplace=True)\n",
    "df.drop('LOR', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRE Score'].fillna(df['GRE Score'].mode()[0],inplace=True)\n",
    "df['TOEFL Score'].fillna(df['TOEFL Score'].mode()[0],inplace=True)\n",
    "df['University Rating'].fillna(df['University Rating'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4.3</th>\n",
       "      <td>319.076923</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>8.537692</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>323.250000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>8.667500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>330.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.5</th>\n",
       "      <td>317.833333</td>\n",
       "      <td>104.833333</td>\n",
       "      <td>8.973333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>323.500000</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.9</th>\n",
       "      <td>314.692308</td>\n",
       "      <td>95.538462</td>\n",
       "      <td>8.346154</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.6</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>7.683333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.4</th>\n",
       "      <td>306.285714</td>\n",
       "      <td>99.571429</td>\n",
       "      <td>6.808571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.6</th>\n",
       "      <td>307.750000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>302.750000</td>\n",
       "      <td>100.625000</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.4</th>\n",
       "      <td>310.500000</td>\n",
       "      <td>105.666667</td>\n",
       "      <td>8.076667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.1</th>\n",
       "      <td>296.285714</td>\n",
       "      <td>97.428571</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.9</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>99.166667</td>\n",
       "      <td>7.318333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.6</th>\n",
       "      <td>313.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.8</th>\n",
       "      <td>288.666667</td>\n",
       "      <td>96.066667</td>\n",
       "      <td>7.646000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67.0</th>\n",
       "      <td>264.428571</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.884286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68.5</th>\n",
       "      <td>300.666667</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>8.040000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.7</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>100.833333</td>\n",
       "      <td>6.776667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>301.285714</td>\n",
       "      <td>100.571429</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.1</th>\n",
       "      <td>215.857143</td>\n",
       "      <td>90.428571</td>\n",
       "      <td>7.688571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82.3</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.0</th>\n",
       "      <td>293.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GRE Score  TOEFL Score      CGPA  Research  \\\n",
       "University Rating                                                \n",
       "4.3                319.076923   109.000000  8.537692  0.692308   \n",
       "7.0                323.250000   114.000000  8.667500  0.750000   \n",
       "13.0               330.000000   111.000000  9.000000  1.000000   \n",
       "15.0               317.000000   110.000000  8.880000  0.000000   \n",
       "16.0               317.000000   110.000000  8.880000  0.000000   \n",
       "17.5               317.833333   104.833333  8.973333  0.666667   \n",
       "20.0               323.500000   110.500000  8.940000  0.000000   \n",
       "29.9               314.692308    95.538462  8.346154  0.461538   \n",
       "36.6               316.000000   107.833333  7.683333  0.333333   \n",
       "38.4               306.285714    99.571429  6.808571  0.428571   \n",
       "39.6               307.750000   103.750000  8.490000  0.500000   \n",
       "42.0               302.750000   100.625000  8.218750  0.750000   \n",
       "46.4               310.500000   105.666667  8.076667  0.500000   \n",
       "47.0               317.000000   110.000000  8.880000  0.000000   \n",
       "50.1               296.285714    97.428571  7.370000  0.571429   \n",
       "55.9               296.000000    99.166667  7.318333  0.333333   \n",
       "63.6               313.000000   104.000000  7.950000  0.500000   \n",
       "65.8               288.666667    96.066667  7.646000  0.533333   \n",
       "67.0               264.428571   104.000000  7.884286  0.571429   \n",
       "68.5               300.666667    98.666667  8.040000  0.500000   \n",
       "70.7               303.000000   100.833333  6.776667  0.500000   \n",
       "71.0               301.285714   100.571429  7.160000  0.428571   \n",
       "80.1               215.857143    90.428571  7.688571  0.571429   \n",
       "82.3               292.000000    87.000000  7.900000  0.000000   \n",
       "99.0               293.000000    92.000000  6.000000  0.000000   \n",
       "\n",
       "                   Chance of Admit  \n",
       "University Rating                   \n",
       "4.3                       0.230769  \n",
       "7.0                       0.500000  \n",
       "13.0                      1.000000  \n",
       "15.0                      0.000000  \n",
       "16.0                      0.000000  \n",
       "17.5                      0.500000  \n",
       "20.0                      1.000000  \n",
       "29.9                      0.461538  \n",
       "36.6                      0.500000  \n",
       "38.4                      0.285714  \n",
       "39.6                      0.750000  \n",
       "42.0                      0.500000  \n",
       "46.4                      0.500000  \n",
       "47.0                      1.000000  \n",
       "50.1                      0.571429  \n",
       "55.9                      0.500000  \n",
       "63.6                      0.250000  \n",
       "65.8                      0.466667  \n",
       "67.0                      0.571429  \n",
       "68.5                      0.500000  \n",
       "70.7                      0.500000  \n",
       "71.0                      0.571429  \n",
       "80.1                      0.571429  \n",
       "82.3                      0.333333  \n",
       "99.0                      1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_university = df.groupby(by='University Rating').mean()\n",
    "df_university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Chance of Admit'],axis=1)\n",
    "y=df['Chance of Admit']\n",
    "# here we are droping the Chance of Admit and serial no, as they are not going to be used for the features \n",
    "# Chance of Admit is the target column which shows the probalility of admission for a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332</td>\n",
       "      <td>110</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>333</td>\n",
       "      <td>113</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338</td>\n",
       "      <td>118</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>90</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  CGPA  Research\n",
       "0        317          110                4.3  8.88         0\n",
       "1        332          110                4.3  8.74         1\n",
       "2        333          113                4.3  9.45         1\n",
       "3        338          118                4.3  9.09         1\n",
       "4        300           90                4.3  8.20         1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head() # checking the transformed feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.21499003e-01,  5.92944357e-01, -1.78623133e+00,\n",
       "         1.01620604e+00, -1.01418511e+00],\n",
       "       [ 6.07186478e-01,  5.92944357e-01, -1.78623133e+00,\n",
       "         8.69590348e-01,  9.86013297e-01],\n",
       "       [ 6.26232310e-01,  7.92308442e-01, -1.78623133e+00,\n",
       "         1.61314135e+00,  9.86013297e-01],\n",
       "       [ 7.21461468e-01,  1.12458192e+00, -1.78623133e+00,\n",
       "         1.23612958e+00,  9.86013297e-01],\n",
       "       [-2.28013477e-03, -7.36149545e-01, -1.78623133e+00,\n",
       "         3.04072683e-01,  9.86013297e-01],\n",
       "       [-2.28013477e-03, -7.16025940e-02, -1.78623133e+00,\n",
       "        -5.96566562e-01,  9.86013297e-01],\n",
       "       [-4.03717981e-02, -7.16025940e-02, -1.78623133e+00,\n",
       "        -5.96566562e-01, -1.01418511e+00],\n",
       "       [ 3.78636498e-01,  5.92944357e-01, -1.78623133e+00,\n",
       "         6.18249164e-01,  9.86013297e-01],\n",
       "       [ 3.97682330e-01,  9.91672528e-01, -1.78623133e+00,\n",
       "         7.96282503e-01, -1.01418511e+00],\n",
       "       [ 2.26269845e-01,  1.12458192e+00, -1.78623133e+00,\n",
       "         9.46216960e-02,  9.86013297e-01],\n",
       "       [ 5.69094815e-01,  6.59399052e-01, -1.78623133e+00,\n",
       "         1.14187663e+00, -1.01418511e+00],\n",
       "       [ 3.21499003e-01,  5.92944357e-01, -1.78623133e+00,\n",
       "         9.11480546e-01,  9.86013297e-01],\n",
       "       [ 5.69094815e-01,  6.59399052e-01, -1.78623133e+00,\n",
       "         1.14187663e+00,  9.86013297e-01],\n",
       "       [ 5.69094815e-01,  6.59399052e-01, -1.67198642e+00,\n",
       "         1.14187663e+00,  9.86013297e-01],\n",
       "       [ 5.69094815e-01,  6.59399052e-01, -1.67198642e+00,\n",
       "         1.14187663e+00,  9.86013297e-01],\n",
       "       [ 3.97682330e-01,  9.91672528e-01, -1.67198642e+00,\n",
       "         7.96282503e-01, -1.01418511e+00],\n",
       "       [ 2.26269845e-01,  1.12458192e+00, -1.67198642e+00,\n",
       "         9.46216960e-02,  9.86013297e-01],\n",
       "       [ 5.69094815e-01,  6.59399052e-01, -1.41810885e+00,\n",
       "         1.14187663e+00,  9.86013297e-01],\n",
       "       [ 3.21499003e-01,  5.92944357e-01, -1.33348299e+00,\n",
       "         1.01620604e+00, -1.01418511e+00],\n",
       "       [ 3.21499003e-01,  5.92944357e-01, -1.29117007e+00,\n",
       "         1.01620604e+00, -1.01418511e+00],\n",
       "       [ 6.64323973e-01,  9.25217832e-01, -1.22770067e+00,\n",
       "         2.00062568e+00,  9.86013297e-01],\n",
       "       [ 4.73865656e-01,  5.92944357e-01, -1.22770067e+00,\n",
       "         2.10535117e+00,  9.86013297e-01],\n",
       "       [ 5.11957320e-01,  4.60034967e-01, -1.22770067e+00,\n",
       "         1.56077861e+00,  9.86013297e-01],\n",
       "       [ 1.31040687e-01, -4.70330765e-01, -1.22770067e+00,\n",
       "        -6.38456759e-01,  9.86013297e-01],\n",
       "       [ 2.45315677e-01,  3.93580272e-01, -1.22770067e+00,\n",
       "         8.27700151e-01, -1.01418511e+00],\n",
       "       [-2.28013477e-03, -4.03876069e-01, -1.22770067e+00,\n",
       "         8.27700151e-01, -1.01418511e+00],\n",
       "       [ 5.69094815e-01,  6.59399052e-01, -1.12191835e+00,\n",
       "         1.14187663e+00, -1.01418511e+00],\n",
       "       [ 3.21499003e-01,  5.92944357e-01, -1.12191835e+00,\n",
       "         1.01620604e+00, -1.01418511e+00],\n",
       "       [ 3.59590667e-01,  9.91672528e-01, -7.03020364e-01,\n",
       "         1.73881195e+00, -1.01418511e+00],\n",
       "       [ 3.59590667e-01,  1.19103661e+00, -7.03020364e-01,\n",
       "         1.04762369e+00,  9.86013297e-01],\n",
       "       [ 4.92911488e-01,  2.60670881e-01, -7.03020364e-01,\n",
       "         1.06856879e+00, -1.01418511e+00],\n",
       "       [ 9.29490235e-02, -1.06842302e+00, -7.03020364e-01,\n",
       "         7.22974657e-01, -1.01418511e+00],\n",
       "       [ 4.54819825e-01,  2.60670881e-01, -7.03020364e-01,\n",
       "        -5.33731265e-01, -1.01418511e+00],\n",
       "       [-2.13259664e-02,  3.27125577e-01, -7.03020364e-01,\n",
       "        -3.66170476e-01,  9.86013297e-01],\n",
       "       [ 3.21499003e-01, -7.16025940e-02, -7.03020364e-01,\n",
       "         2.30764838e-01,  9.86013297e-01],\n",
       "       [ 3.97682330e-01, -7.16025940e-02, -7.03020364e-01,\n",
       "        -1.35774390e-01,  9.86013297e-01],\n",
       "       [ 3.59590667e-01,  3.93580272e-01, -7.03020364e-01,\n",
       "         5.34468769e-01, -1.01418511e+00],\n",
       "       [ 9.29490235e-02, -1.06842302e+00, -7.03020364e-01,\n",
       "         1.14187663e+00, -1.01418511e+00],\n",
       "       [ 1.88178182e-01,  4.60034967e-01, -7.03020364e-01,\n",
       "        -6.38456759e-01,  9.86013297e-01],\n",
       "       [ 2.83407340e-01, -6.71707210e+00, -7.03020364e-01,\n",
       "         1.45605311e+00, -1.01418511e+00],\n",
       "       [ 2.26269845e-01,  3.27125577e-01, -7.03020364e-01,\n",
       "        -3.24280278e-01,  9.86013297e-01],\n",
       "       [ 3.78636498e-01,  7.25853747e-01, -4.19523744e-01,\n",
       "        -2.19554785e-01,  9.86013297e-01],\n",
       "       [ 4.16728161e-01,  3.93580272e-01, -4.19523744e-01,\n",
       "        -5.33731265e-01,  9.86013297e-01],\n",
       "       [ 3.97682330e-01,  1.12458192e+00, -4.19523744e-01,\n",
       "         9.95260941e-01, -1.01418511e+00],\n",
       "       [ 2.64361508e-01,  7.25853747e-01, -4.19523744e-01,\n",
       "        -1.66476660e+00, -1.01418511e+00],\n",
       "       [ 2.07224013e-01,  3.93580272e-01, -4.19523744e-01,\n",
       "        -6.17511660e-01, -1.01418511e+00],\n",
       "       [ 1.50086518e-01, -6.69694850e-01, -4.19523744e-01,\n",
       "         6.18249164e-01, -1.01418511e+00],\n",
       "       [ 2.26269845e-01, -3.37421374e-01, -3.43360473e-01,\n",
       "        -1.88137137e-01, -1.01418511e+00],\n",
       "       [ 3.78636498e-01,  6.59399052e-01, -3.43360473e-01,\n",
       "        -1.16208423e+00,  9.86013297e-01],\n",
       "       [ 1.11994855e-01, -2.04511984e-01, -3.43360473e-01,\n",
       "        -1.01037976e-02, -1.01418511e+00],\n",
       "       [-1.16555125e-01, -1.06842302e+00, -3.43360473e-01,\n",
       "        -1.47626071e+00,  9.86013297e-01],\n",
       "       [ 1.69132350e-01,  4.60034967e-01, -3.43360473e-01,\n",
       "        -1.65429405e+00,  9.86013297e-01],\n",
       "       [-1.16555125e-01, -1.38057289e-01, -3.43360473e-01,\n",
       "        -9.52633240e-01, -1.01418511e+00],\n",
       "       [ 1.69132350e-01, -7.16025940e-02, -3.43360473e-01,\n",
       "        -2.62824114e+00, -1.01418511e+00],\n",
       "       [ 7.39031918e-02,  1.27761491e-01, -2.92584960e-01,\n",
       "         8.48645250e-01,  9.86013297e-01],\n",
       "       [ 3.78636498e-01,  1.12458192e+00, -2.92584960e-01,\n",
       "         1.22565703e+00, -1.01418511e+00],\n",
       "       [ 1.88178182e-01, -5.14789892e-03, -2.92584960e-01,\n",
       "         9.46216960e-02,  9.86013297e-01],\n",
       "       [-5.94176297e-02, -5.36785460e-01, -2.92584960e-01,\n",
       "         2.62182486e-01, -1.01418511e+00],\n",
       "       [ 1.50086518e-01,  5.92944357e-01, -1.91033932e-01,\n",
       "         1.16282173e+00,  9.86013297e-01],\n",
       "       [-3.45105104e-01,  2.60670881e-01, -1.91033932e-01,\n",
       "        -4.60423420e-01,  9.86013297e-01],\n",
       "       [ 3.58115285e-02,  2.60670881e-01, -1.91033932e-01,\n",
       "         1.99347190e-01,  9.86013297e-01],\n",
       "       [ 2.64361508e-01,  6.59399052e-01, -1.91033932e-01,\n",
       "         8.27700151e-01,  9.86013297e-01],\n",
       "       [ 2.26269845e-01,  6.13067962e-02, -1.91033932e-01,\n",
       "         1.99347190e-01, -1.01418511e+00],\n",
       "       [ 1.88178182e-01, -4.03876069e-01, -1.91033932e-01,\n",
       "         1.99347190e-01,  9.86013297e-01],\n",
       "       [-7.84634614e-02, -1.26778711e+00, -1.91033932e-01,\n",
       "         8.27700151e-01, -1.01418511e+00],\n",
       "       [-4.03717981e-02, -4.03876069e-01, -1.91033932e-01,\n",
       "        -3.66170476e-01,  9.86013297e-01],\n",
       "       [ 3.97682330e-01,  4.60034967e-01, -4.85704740e-03,\n",
       "         2.13138505e-02,  9.86013297e-01],\n",
       "       [ 3.40544835e-01,  5.92944357e-01, -4.85704740e-03,\n",
       "         3.56435430e-01, -1.01418511e+00],\n",
       "       [ 3.02453172e-01,  5.92944357e-01, -4.85704740e-03,\n",
       "         1.24660213e+00, -1.01418511e+00],\n",
       "       [ 1.88178182e-01,  6.13067962e-02, -4.85704740e-03,\n",
       "        -9.52633240e-01, -1.01418511e+00],\n",
       "       [-2.28013477e-03,  2.60670881e-01, -4.85704740e-03,\n",
       "        -2.19554785e-01,  9.86013297e-01],\n",
       "       [-4.03717981e-02, -1.38057289e-01, -4.85704740e-03,\n",
       "         5.97304065e-01,  9.86013297e-01],\n",
       "       [ 3.21499003e-01,  5.92944357e-01,  2.05307096e-02,\n",
       "         1.01620604e+00, -1.01418511e+00],\n",
       "       [-2.28013477e-03, -7.16025940e-02,  1.51700787e-01,\n",
       "        -8.58380296e-01,  9.86013297e-01],\n",
       "       [ 1.67656969e-02, -4.70330765e-01,  1.51700787e-01,\n",
       "        -1.14829291e-01, -1.01418511e+00],\n",
       "       [-2.30830115e-01, -7.16025940e-02,  1.51700787e-01,\n",
       "        -3.66170476e-01, -1.01418511e+00],\n",
       "       [-1.92738451e-01, -4.03876069e-01,  1.51700787e-01,\n",
       "        -1.16208423e+00,  9.86013297e-01],\n",
       "       [-2.30830115e-01, -2.04511984e-01,  1.51700787e-01,\n",
       "        -3.66170476e-01, -1.01418511e+00],\n",
       "       [-5.94176297e-02, -2.04511984e-01,  1.51700787e-01,\n",
       "         6.32040479e-02,  9.86013297e-01],\n",
       "       [ 1.88178182e-01, -2.70966679e-01,  1.51700787e-01,\n",
       "        -1.15161168e+00,  9.86013297e-01],\n",
       "       [ 2.83407340e-01,  2.60670881e-01,  3.97115771e-01,\n",
       "        -1.01037976e-02, -1.01418511e+00],\n",
       "       [-5.94176297e-02, -4.03876069e-01,  3.97115771e-01,\n",
       "        -4.29005772e-01,  9.86013297e-01],\n",
       "       [-1.54646788e-01, -7.16025940e-02,  3.97115771e-01,\n",
       "         1.99347190e-01,  9.86013297e-01],\n",
       "       [-2.11784283e-01, -7.16025940e-02,  3.97115771e-01,\n",
       "        -1.05735873e+00, -1.01418511e+00],\n",
       "       [-4.03717981e-02, -4.03876069e-01,  3.97115771e-01,\n",
       "        -1.26680972e+00, -1.01418511e+00],\n",
       "       [-2.87967609e-01, -7.16025940e-02,  3.97115771e-01,\n",
       "        -1.15161168e+00, -1.01418511e+00],\n",
       "       [ 5.31003151e-01,  5.92944357e-01,  7.22925319e-01,\n",
       "        -1.56719489e-01, -1.01418511e+00],\n",
       "       [ 2.45315677e-01, -7.16025940e-02,  7.22925319e-01,\n",
       "        -1.14829291e-01,  9.86013297e-01],\n",
       "       [ 1.67656969e-02, -3.37421374e-01,  7.22925319e-01,\n",
       "         5.03051121e-01,  9.86013297e-01],\n",
       "       [ 1.88178182e-01,  5.92944357e-01,  7.22925319e-01,\n",
       "        -6.24665444e-02, -1.01418511e+00],\n",
       "       [ 3.58115285e-02, -2.04511984e-01,  8.16013761e-01,\n",
       "         1.72833940e+00, -1.01418511e+00],\n",
       "       [ 2.26269845e-01,  2.60670881e-01,  8.16013761e-01,\n",
       "         9.46216960e-02, -1.01418511e+00],\n",
       "       [ 3.02453172e-01,  5.26489662e-01,  8.16013761e-01,\n",
       "        -5.54676364e-01, -1.01418511e+00],\n",
       "       [ 1.31040687e-01,  2.60670881e-01,  8.16013761e-01,\n",
       "         2.20292288e-01, -1.01418511e+00],\n",
       "       [ 1.88178182e-01,  6.13067962e-02,  8.16013761e-01,\n",
       "        -1.43437051e+00, -1.01418511e+00],\n",
       "       [ 1.11994855e-01,  7.25853747e-01,  8.16013761e-01,\n",
       "        -6.07039111e-01,  9.86013297e-01],\n",
       "       [-4.03717981e-02,  2.60670881e-01,  8.16013761e-01,\n",
       "         9.46216960e-02,  9.86013297e-01],\n",
       "       [ 2.26269845e-01,  7.25853747e-01,  8.16013761e-01,\n",
       "        -1.54956855e+00,  9.86013297e-01],\n",
       "       [ 3.02453172e-01, -6.71707210e+00,  8.16013761e-01,\n",
       "         8.27700151e-01,  9.86013297e-01],\n",
       "       [ 1.88178182e-01,  5.92944357e-01,  8.16013761e-01,\n",
       "         8.27700151e-01,  9.86013297e-01],\n",
       "       [ 3.78636498e-01, -1.06842302e+00,  8.16013761e-01,\n",
       "        -3.24280278e-01,  9.86013297e-01],\n",
       "       [ 1.50086518e-01, -1.06842302e+00,  8.16013761e-01,\n",
       "        -5.33731265e-01, -1.01418511e+00],\n",
       "       [-5.71602963e+00,  2.60670881e-01,  8.16013761e-01,\n",
       "        -7.85072450e-01,  9.86013297e-01],\n",
       "       [ 5.48573602e-02,  1.94216186e-01,  8.16013761e-01,\n",
       "        -1.25633717e+00, -1.01418511e+00],\n",
       "       [ 1.88178182e-01,  1.94216186e-01,  8.16013761e-01,\n",
       "        -8.89797944e-01,  9.86013297e-01],\n",
       "       [ 2.64361508e-01,  9.25217832e-01,  8.66789275e-01,\n",
       "         6.60139361e-01, -1.01418511e+00],\n",
       "       [ 1.88178182e-01, -1.38057289e-01,  8.66789275e-01,\n",
       "         1.44558056e+00,  9.86013297e-01],\n",
       "       [ 2.64361508e-01,  6.59399052e-01,  8.66789275e-01,\n",
       "         1.34085507e+00, -1.01418511e+00],\n",
       "       [ 5.48573602e-02, -8.02604240e-01,  8.66789275e-01,\n",
       "        -6.59401858e-01,  9.86013297e-01],\n",
       "       [ 1.11994855e-01,  2.60670881e-01,  8.66789275e-01,\n",
       "        -8.79325394e-01,  9.86013297e-01],\n",
       "       [-5.71602963e+00,  2.60670881e-01,  8.66789275e-01,\n",
       "        -9.38841925e-02,  9.86013297e-01],\n",
       "       [ 7.39031918e-02,  1.94216186e-01,  8.66789275e-01,\n",
       "        -1.99988818e+00, -1.01418511e+00],\n",
       "       [ 1.69132350e-01, -7.16025940e-02,  9.30258667e-01,\n",
       "         1.99347190e-01,  9.86013297e-01],\n",
       "       [ 1.31040687e-01, -2.04511984e-01,  9.30258667e-01,\n",
       "         7.22974657e-01, -1.01418511e+00],\n",
       "       [ 3.97682330e-01,  4.60034967e-01,  9.30258667e-01,\n",
       "         4.08798177e-01,  9.86013297e-01],\n",
       "       [-3.45105104e-01, -4.03876069e-01,  9.30258667e-01,\n",
       "        -9.52633240e-01,  9.86013297e-01],\n",
       "       [-9.75092930e-02, -4.03876069e-01,  9.30258667e-01,\n",
       "         3.56435430e-01, -1.01418511e+00],\n",
       "       [-1.92738451e-01, -3.37421374e-01,  9.30258667e-01,\n",
       "         8.41491466e-02, -1.01418511e+00],\n",
       "       [ 4.73865656e-01, -7.16025940e-02,  1.02334711e+00,\n",
       "         8.27700151e-01, -1.01418511e+00],\n",
       "       [ 1.67656969e-02, -7.16025940e-02,  1.02334711e+00,\n",
       "        -9.94523437e-01,  9.86013297e-01],\n",
       "       [-1.16555125e-01,  2.60670881e-01,  1.02334711e+00,\n",
       "        -6.07039111e-01,  9.86013297e-01],\n",
       "       [-9.75092930e-02, -4.03876069e-01,  1.02334711e+00,\n",
       "        -2.97383527e+00, -1.01418511e+00],\n",
       "       [-2.28013477e-03,  5.92944357e-01,  1.02334711e+00,\n",
       "        -2.62824114e+00, -1.01418511e+00],\n",
       "       [ 5.48573602e-02, -4.03876069e-01,  1.02334711e+00,\n",
       "        -7.43182253e-01,  9.86013297e-01],\n",
       "       [ 1.88178182e-01,  2.60670881e-01,  1.03604099e+00,\n",
       "        -1.37153521e+00,  9.86013297e-01],\n",
       "       [-2.13259664e-02,  6.59399052e-01,  1.03604099e+00,\n",
       "        -1.14829291e-01,  9.86013297e-01],\n",
       "       [ 4.16728161e-01, -6.03240155e-01,  1.03604099e+00,\n",
       "         5.86831516e-01, -1.01418511e+00],\n",
       "       [-2.28013477e-03, -2.04511984e-01,  1.03604099e+00,\n",
       "        -7.22237154e-01, -1.01418511e+00],\n",
       "       [-2.11784283e-01, -2.04511984e-01,  1.03604099e+00,\n",
       "        -1.54956855e+00, -1.01418511e+00],\n",
       "       [-4.02242599e-01,  2.60670881e-01,  1.03604099e+00,\n",
       "        -9.42160690e-01,  9.86013297e-01],\n",
       "       [ 1.88178182e-01, -4.03876069e-01,  1.03604099e+00,\n",
       "        -1.38200776e+00, -1.01418511e+00],\n",
       "       [ 1.69132350e-01,  2.60670881e-01,  1.42108863e+00,\n",
       "        -4.29005772e-01,  9.86013297e-01],\n",
       "       [ 3.58115285e-02, -1.06842302e+00,  1.42108863e+00,\n",
       "         7.33447207e-01, -1.01418511e+00],\n",
       "       [-4.03717981e-02, -8.69058935e-01,  1.42108863e+00,\n",
       "         9.11480546e-01,  9.86013297e-01],\n",
       "       [-2.28013477e-03, -1.06842302e+00,  1.42108863e+00,\n",
       "        -1.04356742e-01,  9.86013297e-01],\n",
       "       [ 3.58115285e-02,  6.13067962e-02,  1.42108863e+00,\n",
       "        -2.29311956e+00, -1.01418511e+00],\n",
       "       [-5.71602963e+00, -2.06524345e+00,  1.42108863e+00,\n",
       "        -3.24280278e-01, -1.01418511e+00],\n",
       "       [-5.71602963e+00, -2.04511984e-01,  1.42108863e+00,\n",
       "        -1.14829291e-01,  9.86013297e-01],\n",
       "       [-1.92738451e-01, -7.36149545e-01,  1.51417708e+00,\n",
       "        -4.29005772e-01, -1.01418511e+00],\n",
       "       [-2.13259664e-02, -7.36149545e-01,  1.51417708e+00,\n",
       "         5.13523670e-01, -1.01418511e+00],\n",
       "       [-2.49875946e-01, -1.33424180e+00,  1.51417708e+00,\n",
       "        -1.14829291e-01, -1.01418511e+00],\n",
       "       [-1.35600956e-01, -6.03240155e-01,  2.22080298e+00,\n",
       "        -1.99988818e+00, -1.01418511e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be only used if you want to scale the data,standize the data,if the variation is huge in the dataset\n",
    "# when we have huge variation in the data set\n",
    "# i am not changing the data , i am changing the scale only like taking logs, sqrt--not changing the actual meaning of the data set\n",
    "# variance betweeen the dataset become very low\n",
    "# machine will understand in better way this data  as having low variance in the data set\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_feature=StandardScaler()\n",
    "scaler_lablel=StandardScaler()\n",
    "scaled_data=scaler_feature.fit_transform(x)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.33,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5721252162349213"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.005972\n",
      "TOEFL Score           0.010743\n",
      "University Rating     0.020667\n",
      "CGPA                  0.521159\n",
      "Research              0.711443\n",
      "Feature: 0, Score: 0.00597\n",
      "Feature: 1, Score: 0.01074\n",
      "Feature: 2, Score: 0.02067\n",
      "Feature: 3, Score: 0.52116\n",
      "Feature: 4, Score: 0.71144\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "intercept = reg.intercept_\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = reg.coef_[0]\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.01,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7888646858055886"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#tf.keras.layers.Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 50)                300       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 150)               7650      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 150)               22650     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                7550      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,201\n",
      "Trainable params: 38,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN_model = keras.Sequential()\n",
    "ANN_model.add(Dense(50, input_dim = 5))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(50))\n",
    "ANN_model.add(Activation('linear'))\n",
    "ANN_model.add(Dense(1))\n",
    "ANN_model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 28ms/step - loss: 1355.8209 - val_loss: 6.1519\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 922.3366 - val_loss: 16.6332\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 575.3069 - val_loss: 11.7152\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 298.9996 - val_loss: 1.6015\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 174.2974 - val_loss: 1.6504\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 107.6642 - val_loss: 1.5138\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 88.4880 - val_loss: 2.7899\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 45.9630 - val_loss: 6.3357\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 38.3168 - val_loss: 1.6999\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 23.6462 - val_loss: 1.2973\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 38.1789 - val_loss: 1.0436\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 33.0279 - val_loss: 1.9978\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 22.6284 - val_loss: 1.2856\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 16.0825 - val_loss: 1.1711\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 12.7598 - val_loss: 1.1636\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 14.7802 - val_loss: 1.0767\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 14.9881 - val_loss: 1.2244\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 11.8150 - val_loss: 1.3092\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.9961 - val_loss: 1.3911\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.5450 - val_loss: 1.3155\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0929 - val_loss: 1.4115\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5059 - val_loss: 1.1429\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.4930 - val_loss: 1.0889\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1757 - val_loss: 2.1073\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.4551 - val_loss: 1.4614\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.7045 - val_loss: 1.1876\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.7285 - val_loss: 1.0555\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6.6477 - val_loss: 1.2417\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4981 - val_loss: 1.2405\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2096 - val_loss: 1.0077\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.5000 - val_loss: 1.0594\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6956 - val_loss: 1.0586\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6812 - val_loss: 1.0382\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.7780 - val_loss: 1.0559\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.7875 - val_loss: 0.9948\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3.1224 - val_loss: 1.0183\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3710 - val_loss: 1.0049\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8330 - val_loss: 1.0082\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9899 - val_loss: 0.9957\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.1628 - val_loss: 0.9936\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9400 - val_loss: 0.9944\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0680 - val_loss: 1.0526\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.5780 - val_loss: 1.0016\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1649 - val_loss: 1.0030\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8458 - val_loss: 1.0286\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.4870 - val_loss: 1.0179\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 2.5766 - val_loss: 1.0175\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8286 - val_loss: 1.0154\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8317 - val_loss: 1.0609\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3982 - val_loss: 1.0011\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9436 - val_loss: 1.0030\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.3010 - val_loss: 1.0183\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.9757 - val_loss: 1.0102\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9344 - val_loss: 0.9998\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.9907 - val_loss: 1.0103\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6964 - val_loss: 0.9990\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.7275 - val_loss: 0.9986\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.8350 - val_loss: 1.0087\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8122 - val_loss: 1.0274\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7270 - val_loss: 1.0517\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6766 - val_loss: 1.0049\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8025 - val_loss: 1.0257\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8289 - val_loss: 1.0640\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0963 - val_loss: 1.0143\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8759 - val_loss: 1.0394\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8444 - val_loss: 1.0620\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.9445 - val_loss: 1.0170\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.4265 - val_loss: 1.0033\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5516 - val_loss: 0.9995\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2598 - val_loss: 1.0003\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5034 - val_loss: 1.0260\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1887 - val_loss: 1.0073\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.5435 - val_loss: 1.0044\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.4045 - val_loss: 1.0340\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2926 - val_loss: 0.9994\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7093 - val_loss: 1.0348\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3565 - val_loss: 1.0518\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3825 - val_loss: 1.0679\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5630 - val_loss: 1.0510\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.6693 - val_loss: 1.0070\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6014 - val_loss: 1.0029\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0903 - val_loss: 1.0423\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5288 - val_loss: 1.0600\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2390 - val_loss: 1.0081\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3237 - val_loss: 1.0297\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2874 - val_loss: 1.0070\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2756 - val_loss: 1.0086\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.6923 - val_loss: 1.0191\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5429 - val_loss: 1.0089\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3560 - val_loss: 1.0038\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3925 - val_loss: 1.0016\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1905 - val_loss: 1.0055\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.4483 - val_loss: 1.0084\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1880 - val_loss: 1.0074\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3005 - val_loss: 1.0084\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2427 - val_loss: 1.0793\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4649 - val_loss: 1.0016\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2789 - val_loss: 1.0106\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3754 - val_loss: 1.0204\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3550 - val_loss: 1.0125\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = ANN_model.fit(train_x, train_y, epochs = 100, batch_size = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0452\n",
      "Accuracy : -0.045213937759399414\n"
     ]
    }
   ],
   "source": [
    "result = ANN_model.evaluate(test_x, test_y)\n",
    "accuracy_ANN = 1 - result\n",
    "print(\"Accuracy : {}\".format(accuracy_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x200b3519e20>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend(['Training Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decesion Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree builds regression or classification models in the form of a tree structure. \n",
    "# Decision tree breaks down a dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "# The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree_model = DecisionTreeRegressor()\n",
    "decisionTree_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.351924\n",
      "TOEFL Score           0.092115\n",
      "University Rating     0.269976\n",
      "CGPA                  0.246157\n",
      "Research              0.039828\n",
      "Feature: 0, Score: 0.35192\n",
      "Feature: 1, Score: 0.09211\n",
      "Feature: 2, Score: 0.26998\n",
      "Feature: 3, Score: 0.24616\n",
      "Feature: 4, Score: 0.03983\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = decisionTree_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decisionTree = decisionTree_model.score(test_x, test_y)\n",
    "accuracy_decisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhus\\AppData\\Local\\Temp/ipykernel_1384/2085754441.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_model.fit(train_x, train_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForest_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "randomForest_model.fit(train_x, train_y)\n",
    "accuracy_randomforest = randomForest_model.score(test_x, test_y)\n",
    "accuracy_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.335993\n",
      "TOEFL Score           0.106569\n",
      "University Rating     0.255471\n",
      "CGPA                  0.253954\n",
      "Research              0.048013\n",
      "Feature: 0, Score: 0.33599\n",
      "Feature: 1, Score: 0.10657\n",
      "Feature: 2, Score: 0.25547\n",
      "Feature: 3, Score: 0.25395\n",
      "Feature: 4, Score: 0.04801\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = randomForest_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model to the local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename='finalized_model.pickle'\n",
    "#pickle.dump(reg,open(filename,'wb'))\n",
    "dump(randomForest_model, 'filename.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
