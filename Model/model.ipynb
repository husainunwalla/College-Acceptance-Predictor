{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- ### The goal here is to find the chance of admission of a candidate based on his/her GRE score, TOEFL score, rating of the university in which he/she is trying to get admission,strength of the SOP,Strength of the letter of the recommendation, CGPA and the research experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Prediction.csv\")  # importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.', axis=1, inplace=True)\n",
    "df.drop('SOP', axis=1, inplace=True)\n",
    "df.drop('LOR', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRE Score'].fillna(df['GRE Score'].mode()[0],inplace=True)\n",
    "df['TOEFL Score'].fillna(df['TOEFL Score'].mode()[0],inplace=True)\n",
    "df['University Rating'].fillna(df['University Rating'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4.3</th>\n",
       "      <td>316.857143</td>\n",
       "      <td>105.857143</td>\n",
       "      <td>8.434286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.5</th>\n",
       "      <td>317.833333</td>\n",
       "      <td>104.833333</td>\n",
       "      <td>8.973333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.9</th>\n",
       "      <td>314.692308</td>\n",
       "      <td>95.538462</td>\n",
       "      <td>8.346154</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.6</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>7.683333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.4</th>\n",
       "      <td>306.285714</td>\n",
       "      <td>99.571429</td>\n",
       "      <td>6.808571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.6</th>\n",
       "      <td>307.750000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>302.750000</td>\n",
       "      <td>100.625000</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.4</th>\n",
       "      <td>310.500000</td>\n",
       "      <td>105.666667</td>\n",
       "      <td>8.076667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.1</th>\n",
       "      <td>296.285714</td>\n",
       "      <td>97.428571</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.9</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>99.166667</td>\n",
       "      <td>7.318333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.6</th>\n",
       "      <td>313.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.8</th>\n",
       "      <td>288.666667</td>\n",
       "      <td>96.066667</td>\n",
       "      <td>7.646000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67.0</th>\n",
       "      <td>264.428571</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.884286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68.5</th>\n",
       "      <td>300.666667</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>8.040000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.7</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>100.833333</td>\n",
       "      <td>6.776667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>301.285714</td>\n",
       "      <td>100.571429</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.1</th>\n",
       "      <td>215.857143</td>\n",
       "      <td>90.428571</td>\n",
       "      <td>7.688571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82.3</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.0</th>\n",
       "      <td>293.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GRE Score  TOEFL Score      CGPA  Research  \\\n",
       "University Rating                                                \n",
       "4.3                316.857143   105.857143  8.434286  0.714286   \n",
       "15.0               317.000000   110.000000  8.880000  0.000000   \n",
       "16.0               317.000000   110.000000  8.880000  0.000000   \n",
       "17.5               317.833333   104.833333  8.973333  0.666667   \n",
       "20.0               317.000000   110.000000  8.880000  0.000000   \n",
       "29.9               314.692308    95.538462  8.346154  0.461538   \n",
       "36.6               316.000000   107.833333  7.683333  0.333333   \n",
       "38.4               306.285714    99.571429  6.808571  0.428571   \n",
       "39.6               307.750000   103.750000  8.490000  0.500000   \n",
       "42.0               302.750000   100.625000  8.218750  0.750000   \n",
       "46.4               310.500000   105.666667  8.076667  0.500000   \n",
       "47.0               317.000000   110.000000  8.880000  0.000000   \n",
       "50.1               296.285714    97.428571  7.370000  0.571429   \n",
       "55.9               296.000000    99.166667  7.318333  0.333333   \n",
       "63.6               313.000000   104.000000  7.950000  0.500000   \n",
       "65.8               288.666667    96.066667  7.646000  0.533333   \n",
       "67.0               264.428571   104.000000  7.884286  0.571429   \n",
       "68.5               300.666667    98.666667  8.040000  0.500000   \n",
       "70.7               303.000000   100.833333  6.776667  0.500000   \n",
       "71.0               301.285714   100.571429  7.160000  0.428571   \n",
       "80.1               215.857143    90.428571  7.688571  0.571429   \n",
       "82.3               292.000000    87.000000  7.900000  0.000000   \n",
       "99.0               293.000000    92.000000  6.000000  0.000000   \n",
       "\n",
       "                   Chance of Admit  \n",
       "University Rating                   \n",
       "4.3                       0.428571  \n",
       "15.0                      0.000000  \n",
       "16.0                      0.000000  \n",
       "17.5                      0.500000  \n",
       "20.0                      1.000000  \n",
       "29.9                      0.461538  \n",
       "36.6                      0.500000  \n",
       "38.4                      0.285714  \n",
       "39.6                      0.750000  \n",
       "42.0                      0.500000  \n",
       "46.4                      0.500000  \n",
       "47.0                      1.000000  \n",
       "50.1                      0.571429  \n",
       "55.9                      0.500000  \n",
       "63.6                      0.250000  \n",
       "65.8                      0.466667  \n",
       "67.0                      0.571429  \n",
       "68.5                      0.500000  \n",
       "70.7                      0.500000  \n",
       "71.0                      0.571429  \n",
       "80.1                      0.571429  \n",
       "82.3                      0.333333  \n",
       "99.0                      1.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_university = df.groupby(by='University Rating').mean()\n",
    "df_university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Chance of Admit'],axis=1)\n",
    "y=df['Chance of Admit']\n",
    "# here we are droping the Chance of Admit and serial no, as they are not going to be used for the features \n",
    "# Chance of Admit is the target column which shows the probalility of admission for a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  CGPA  Research\n",
       "0        317          110               47.0  8.88         0\n",
       "1        317          110               16.0  8.88         0\n",
       "2        317          110                4.3  8.88         0\n",
       "3        317          110               20.0  8.88         0\n",
       "4        317          110               15.0  8.88         0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head() # checking the transformed feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.50595114e-01,  6.56243559e-01, -1.47630258e-01,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.60476947e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -2.15472202e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.41675151e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.65177396e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [-9.11887131e-02, -5.24086900e-01,  2.29660326e+00,\n",
       "        -1.91521827e+00, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -6.55234729e-01,  1.51162827e+00,\n",
       "        -3.49644752e-01, -9.84731928e-01],\n",
       "       [ 1.92572438e-02, -6.55234729e-01,  1.51162827e+00,\n",
       "         5.89699359e-01, -9.84731928e-01],\n",
       "       [-2.01634670e-01, -1.24539996e+00,  1.51162827e+00,\n",
       "        -3.65300488e-02, -9.84731928e-01],\n",
       "       [ 5.53079369e-01,  6.56243559e-01,  6.32644289e-01,\n",
       "        -7.82786759e-02, -9.84731928e-01],\n",
       "       [ 2.76964476e-01,  5.04414726e-04,  6.32644289e-01,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 5.60725627e-02, -2.61791243e-01,  6.32644289e-01,\n",
       "         5.79262202e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  6.56243559e-01,  6.32644289e-01,\n",
       "         1.56557352e-02, -9.84731928e-01],\n",
       "       [ 6.26710006e-01,  6.56243559e-01, -2.15472202e+00,\n",
       "         9.44562689e-01,  1.01550480e+00],\n",
       "       [ 6.45117666e-01,  8.52965302e-01, -2.15472202e+00,\n",
       "         1.68560082e+00,  1.01550480e+00],\n",
       "       [ 7.37155963e-01,  1.18083487e+00, -2.15472202e+00,\n",
       "         1.30986318e+00,  1.01550480e+00],\n",
       "       [ 3.76649032e-02, -6.55234729e-01, -2.15472202e+00,\n",
       "         3.80956223e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02,  5.04414726e-04, -2.15472202e+00,\n",
       "        -5.16639261e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04,  5.04414726e-04, -2.15472202e+00,\n",
       "        -5.16639261e-01, -9.84731928e-01],\n",
       "       [ 4.97856390e-01,  5.04414726e-04,  9.66376173e-01,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 5.60725627e-02,  5.04414726e-04,  9.66376173e-01,\n",
       "        -9.13251219e-01,  1.01550480e+00],\n",
       "       [-7.27810536e-02,  3.28373987e-01,  9.66376173e-01,\n",
       "        -5.27076418e-01,  1.01550480e+00],\n",
       "       [-5.43733941e-02, -3.27365157e-01,  9.66376173e-01,\n",
       "        -2.88587385e+00, -9.84731928e-01],\n",
       "       [ 3.76649032e-02,  6.56243559e-01,  9.66376173e-01,\n",
       "        -2.54144768e+00, -9.84731928e-01],\n",
       "       [ 9.28878817e-02, -3.27365157e-01,  9.66376173e-01,\n",
       "        -6.62759456e-01,  1.01550480e+00],\n",
       "       [ 6.81932985e-01,  9.84113131e-01, -1.53426274e+00,\n",
       "         2.07177562e+00,  1.01550480e+00],\n",
       "       [ 4.97856390e-01,  6.56243559e-01, -1.53426274e+00,\n",
       "         2.17614719e+00,  1.01550480e+00],\n",
       "       [ 5.34671709e-01,  5.25095730e-01, -1.53426274e+00,\n",
       "         1.63341504e+00,  1.01550480e+00],\n",
       "       [ 1.66518520e-01, -3.92939072e-01, -1.53426274e+00,\n",
       "        -5.58387888e-01,  1.01550480e+00],\n",
       "       [ 2.76964476e-01,  4.59521815e-01, -1.53426274e+00,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02, -3.27365157e-01, -1.53426274e+00,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 4.05818093e-01,  7.87391387e-01, -6.36476963e-01,\n",
       "        -1.40901617e-01,  1.01550480e+00],\n",
       "       [ 4.42633412e-01,  4.59521815e-01, -6.36476963e-01,\n",
       "        -4.54016320e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  1.18083487e+00, -6.36476963e-01,\n",
       "         1.06980857e+00, -9.84731928e-01],\n",
       "       [ 2.95372136e-01,  7.87391387e-01, -6.36476963e-01,\n",
       "        -1.58122925e+00, -9.84731928e-01],\n",
       "       [ 2.40149157e-01,  4.59521815e-01, -6.36476963e-01,\n",
       "        -5.37513575e-01, -9.84731928e-01],\n",
       "       [ 1.84926179e-01, -5.89660815e-01, -6.36476963e-01,\n",
       "         6.94070926e-01, -9.84731928e-01],\n",
       "       [ 3.87410433e-01,  1.04968705e+00, -9.51407051e-01,\n",
       "         1.81084670e+00, -9.84731928e-01],\n",
       "       [ 3.87410433e-01,  1.24640879e+00, -9.51407051e-01,\n",
       "         1.12199435e+00,  1.01550480e+00],\n",
       "       [ 5.16264050e-01,  3.28373987e-01, -9.51407051e-01,\n",
       "         1.14286867e+00, -9.84731928e-01],\n",
       "       [ 1.29703201e-01, -9.83104301e-01, -9.51407051e-01,\n",
       "         7.98442494e-01, -9.84731928e-01],\n",
       "       [ 4.79448731e-01,  3.28373987e-01, -9.51407051e-01,\n",
       "        -4.54016320e-01, -9.84731928e-01],\n",
       "       [ 1.92572438e-02,  3.93947901e-01, -9.51407051e-01,\n",
       "        -2.87021812e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  5.25095730e-01, -1.75832953e-01,\n",
       "         9.91529895e-02,  1.01550480e+00],\n",
       "       [ 3.69002774e-01,  6.56243559e-01, -1.75832953e-01,\n",
       "         4.33142007e-01, -9.84731928e-01],\n",
       "       [ 3.32187455e-01,  6.56243559e-01, -1.75832953e-01,\n",
       "         1.32030033e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  1.31652244e-01, -1.75832953e-01,\n",
       "        -8.71502592e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02,  3.28373987e-01, -1.75832953e-01,\n",
       "        -1.40901617e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04, -6.50694997e-02, -1.75832953e-01,\n",
       "         6.73196613e-01,  1.01550480e+00],\n",
       "       [ 1.84926179e-01,  6.56243559e-01, -3.82652712e-01,\n",
       "         1.23680308e+00,  1.01550480e+00],\n",
       "       [-2.93672967e-01,  3.28373987e-01, -3.82652712e-01,\n",
       "        -3.80956223e-01,  1.01550480e+00],\n",
       "       [ 7.44802222e-02,  3.28373987e-01, -3.82652712e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [ 2.95372136e-01,  7.21817473e-01, -3.82652712e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01,  1.31652244e-01, -3.82652712e-01,\n",
       "         2.76584655e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01, -3.27365157e-01, -3.82652712e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [-3.59657347e-02, -1.17982604e+00, -3.82652712e-01,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -3.27365157e-01, -3.82652712e-01,\n",
       "        -2.87021812e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02,  5.04414726e-04, -1.91633693e-03,\n",
       "        -7.77568181e-01,  1.01550480e+00],\n",
       "       [ 5.60725627e-02, -3.92939072e-01, -1.91633693e-03,\n",
       "        -3.65300488e-02, -9.84731928e-01],\n",
       "       [-1.83227010e-01,  5.04414726e-04, -1.91633693e-03,\n",
       "        -2.87021812e-01, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -3.27365157e-01, -1.91633693e-03,\n",
       "        -1.08024573e+00,  1.01550480e+00],\n",
       "       [ 3.13779795e-01,  3.28373987e-01,  2.70709710e-01,\n",
       "         6.78415191e-02, -9.84731928e-01],\n",
       "       [-1.75580752e-02, -3.27365157e-01,  2.70709710e-01,\n",
       "        -3.49644752e-01,  1.01550480e+00],\n",
       "       [-1.09596373e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [-1.64819351e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "        -9.75874160e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -3.27365157e-01,  2.70709710e-01,\n",
       "        -1.18461730e+00, -9.84731928e-01],\n",
       "       [-2.38449989e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "        -1.06980857e+00, -9.84731928e-01],\n",
       "       [ 2.03333838e-01,  5.04414726e-04,  8.62966294e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [ 1.66518520e-01, -1.30643414e-01,  8.62966294e-01,\n",
       "         7.98442494e-01, -9.84731928e-01],\n",
       "       [ 4.24225752e-01,  5.25095730e-01,  8.62966294e-01,\n",
       "         4.85327791e-01,  1.01550480e+00],\n",
       "       [-2.93672967e-01, -3.27365157e-01,  8.62966294e-01,\n",
       "        -8.71502592e-01,  1.01550480e+00],\n",
       "       [-5.43733941e-02, -3.27365157e-01,  8.62966294e-01,\n",
       "         4.33142007e-01, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -2.61791243e-01,  8.62966294e-01,\n",
       "         1.61775930e-01, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  5.04414726e-04, -9.51407051e-01,\n",
       "         3.07896125e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  5.04414726e-04, -9.51407051e-01,\n",
       "        -5.74043623e-02,  1.01550480e+00],\n",
       "       [ 3.87410433e-01,  4.59521815e-01, -9.51407051e-01,\n",
       "         6.10573672e-01, -9.84731928e-01],\n",
       "       [ 1.29703201e-01, -9.83104301e-01, -9.51407051e-01,\n",
       "         1.21592877e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  5.25095730e-01, -9.51407051e-01,\n",
       "        -5.58387888e-01,  1.01550480e+00],\n",
       "       [ 3.13779795e-01, -6.55688702e+00, -9.51407051e-01,\n",
       "         1.52904347e+00, -9.84731928e-01],\n",
       "       [ 2.58556817e-01,  3.93947901e-01, -9.51407051e-01,\n",
       "        -2.45273185e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01, -2.61791243e-01, -5.51868879e-01,\n",
       "        -1.09590146e-01, -9.84731928e-01],\n",
       "       [ 4.05818093e-01,  7.21817473e-01, -5.51868879e-01,\n",
       "        -1.08024573e+00,  1.01550480e+00],\n",
       "       [ 1.48110860e-01, -1.30643414e-01, -5.51868879e-01,\n",
       "         6.78415191e-02, -9.84731928e-01],\n",
       "       [-7.27810536e-02, -9.83104301e-01, -5.51868879e-01,\n",
       "        -1.39336043e+00,  1.01550480e+00],\n",
       "       [ 2.03333838e-01,  5.25095730e-01, -5.51868879e-01,\n",
       "        -1.57079210e+00,  1.01550480e+00],\n",
       "       [-7.27810536e-02, -6.50694997e-02, -5.51868879e-01,\n",
       "        -8.71502592e-01, -9.84731928e-01],\n",
       "       [ 2.03333838e-01,  5.04414726e-04, -5.51868879e-01,\n",
       "        -2.54144768e+00, -9.84731928e-01],\n",
       "       [-1.83227010e-01, -1.30643414e-01, -1.91633693e-03,\n",
       "        -2.87021812e-01, -9.84731928e-01],\n",
       "       [-1.75580752e-02, -1.30643414e-01, -1.91633693e-03,\n",
       "         1.40901617e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01, -1.96217328e-01, -1.91633693e-03,\n",
       "        -1.06980857e+00,  1.01550480e+00],\n",
       "       [ 7.44802222e-02, -1.30643414e-01,  7.36054169e-01,\n",
       "         1.80040955e+00, -9.84731928e-01],\n",
       "       [ 2.58556817e-01,  3.28373987e-01,  7.36054169e-01,\n",
       "         1.72213087e-01, -9.84731928e-01],\n",
       "       [ 3.32187455e-01,  5.90669644e-01,  7.36054169e-01,\n",
       "        -4.74890634e-01, -9.84731928e-01],\n",
       "       [ 1.66518520e-01,  3.28373987e-01,  7.36054169e-01,\n",
       "         2.97458968e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  1.31652244e-01,  7.36054169e-01,\n",
       "        -1.35161180e+00, -9.84731928e-01],\n",
       "       [ 1.48110860e-01,  7.87391387e-01,  7.36054169e-01,\n",
       "        -5.27076418e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04,  3.28373987e-01,  7.36054169e-01,\n",
       "         1.72213087e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01,  7.87391387e-01,  7.36054169e-01,\n",
       "        -1.46642053e+00,  1.01550480e+00],\n",
       "       [ 2.03333838e-01,  3.28373987e-01,  1.40821839e+00,\n",
       "        -3.49644752e-01,  1.01550480e+00],\n",
       "       [ 7.44802222e-02, -9.83104301e-01,  1.40821839e+00,\n",
       "         8.08879651e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -7.86382558e-01,  1.40821839e+00,\n",
       "         9.86311317e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02, -9.83104301e-01,  1.40821839e+00,\n",
       "        -2.60928920e-02,  1.01550480e+00],\n",
       "       [ 7.44802222e-02,  1.31652244e-01,  1.40821839e+00,\n",
       "        -2.20745866e+00, -9.84731928e-01],\n",
       "       [-5.48463294e+00, -1.96671302e+00,  1.40821839e+00,\n",
       "        -2.45273185e-01, -9.84731928e-01],\n",
       "       [-5.48463294e+00, -1.30643414e-01,  1.40821839e+00,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 3.32187455e-01, -6.55688702e+00,  7.36054169e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  6.56243559e-01,  7.36054169e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 4.05818093e-01, -9.83104301e-01,  7.36054169e-01,\n",
       "        -2.45273185e-01,  1.01550480e+00],\n",
       "       [ 1.84926179e-01, -9.83104301e-01,  7.36054169e-01,\n",
       "        -4.54016320e-01, -9.84731928e-01],\n",
       "       [-5.48463294e+00,  3.28373987e-01,  7.36054169e-01,\n",
       "        -7.04508083e-01,  1.01550480e+00],\n",
       "       [ 9.28878817e-02,  2.62800072e-01,  7.36054169e-01,\n",
       "        -1.17418014e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  2.62800072e-01,  7.36054169e-01,\n",
       "        -8.08879651e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  3.28373987e-01,  9.80477521e-01,\n",
       "        -1.28898886e+00,  1.01550480e+00],\n",
       "       [ 1.92572438e-02,  7.21817473e-01,  9.80477521e-01,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 4.42633412e-01, -5.24086900e-01,  9.80477521e-01,\n",
       "         6.62759456e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02, -1.30643414e-01,  9.80477521e-01,\n",
       "        -6.41885143e-01, -9.84731928e-01],\n",
       "       [-1.64819351e-01, -1.30643414e-01,  9.80477521e-01,\n",
       "        -1.46642053e+00, -9.84731928e-01],\n",
       "       [-3.48895946e-01,  3.28373987e-01,  9.80477521e-01,\n",
       "        -8.61065435e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01, -3.27365157e-01,  9.80477521e-01,\n",
       "        -1.29942602e+00, -9.84731928e-01],\n",
       "       [ 2.95372136e-01,  9.84113131e-01,  7.92459558e-01,\n",
       "         7.35819554e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01, -6.50694997e-02,  7.92459558e-01,\n",
       "         1.51860631e+00,  1.01550480e+00],\n",
       "       [ 2.95372136e-01,  7.21817473e-01,  7.92459558e-01,\n",
       "         1.41423474e+00, -9.84731928e-01],\n",
       "       [ 9.28878817e-02, -7.20808644e-01,  7.92459558e-01,\n",
       "        -5.79262202e-01,  1.01550480e+00],\n",
       "       [ 1.48110860e-01,  3.28373987e-01,  7.92459558e-01,\n",
       "        -7.98442494e-01,  1.01550480e+00],\n",
       "       [-5.48463294e+00,  3.28373987e-01,  7.92459558e-01,\n",
       "        -1.56557352e-02,  1.01550480e+00],\n",
       "       [ 1.11295541e-01,  2.62800072e-01,  7.92459558e-01,\n",
       "        -1.91521827e+00, -9.84731928e-01],\n",
       "       [ 1.11295541e-01,  1.97226158e-01, -4.95463490e-01,\n",
       "         9.23688376e-01,  1.01550480e+00],\n",
       "       [ 4.05818093e-01,  1.18083487e+00, -4.95463490e-01,\n",
       "         1.29942602e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  6.60783291e-02, -4.95463490e-01,\n",
       "         1.72213087e-01,  1.01550480e+00],\n",
       "       [-1.75580752e-02, -4.58512986e-01, -4.95463490e-01,\n",
       "         3.39207596e-01, -9.84731928e-01]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be only used if you want to scale the data,standize the data,if the variation is huge in the dataset\n",
    "# when we have huge variation in the data set\n",
    "# i am not changing the data , i am changing the scale only like taking logs, sqrt--not changing the actual meaning of the data set\n",
    "# variance betweeen the dataset become very low\n",
    "# machine will understand in better way this data  as having low variance in the data set\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_feature=StandardScaler()\n",
    "scaler_lablel=StandardScaler()\n",
    "scaled_data=scaler_feature.fit_transform(x)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.33,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7868583905683451"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.004019\n",
      "TOEFL Score           0.016411\n",
      "University Rating     0.018374\n",
      "CGPA                  0.555673\n",
      "Research              0.501356\n",
      "Feature: 0, Score: 0.00402\n",
      "Feature: 1, Score: 0.01641\n",
      "Feature: 2, Score: 0.01837\n",
      "Feature: 3, Score: 0.55567\n",
      "Feature: 4, Score: 0.50136\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMgUlEQVR4nO3dYYhd+VnH8e/PyQZFkYIZaEmyTdDgGmS3ljGtVFCLC9ndYlosmFVb1JYQMdqCxcY3Bemb7hsp2mgINRRRDIXWEtrIUrRSoa1mtm4Xs9vIEFcyZmWnW+26WJpm+/hi7pbr5GbmTHZm7uaZ7weGveecP/c+h2y+HE7uvZOqQpJ05/ueaQ8gSdoYBl2SmjDoktSEQZekJgy6JDWxY1ovvGvXrtq3b9+0Xl6S7kiPPfbY16pqdtKxqQV93759zM/PT+vlJemOlOTfb3XMWy6S1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxNQ+KSpp/fad/My0R9gQT3/ooWmP0JJX6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGBT0JIeTXE6ykOTkhOM/m+QbSR4f/Xxg40eVJK1mzd9YlGQGOAXcDywCF5Ocr6onVyz9h6p6yybMKEkaYMgV+iFgoaquVNV14BxwZHPHkiSt15DfKbobuDq2vQi8YcK6n0ryFeAa8L6qurRyQZJjwDGAu+++e/3TStq2uvw+Vdi836k65Ao9E/bViu0vA6+tqvuAPwY+NemJqupMVc1V1dzs7Oy6BpUkrW5I0BeBvWPbe1i+Cv+uqnq+ql4YPb4A3JVk14ZNKUla05CgXwQOJNmfZCdwFDg/viDJq5Nk9PjQ6Hmf2+hhJUm3tuY99Kq6keQE8CgwA5ytqktJjo+OnwbeDvxmkhvAN4GjVbXytowkaRMN+UfRl26jXFix7/TY448AH9nY0SRJ6+EnRSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGBT0JIeTXE6ykOTkKut+MsmLSd6+cSNKkoZYM+hJZoBTwAPAQeDhJAdvse4R4NGNHlKStLYhV+iHgIWqulJV14FzwJEJ634b+ATw7AbOJ0kaaEjQdwNXx7YXR/u+K8lu4G3A6dWeKMmxJPNJ5peWltY7qyRpFUOCngn7asX2h4H3V9WLqz1RVZ2pqrmqmpudnR04oiRpiB0D1iwCe8e29wDXVqyZA84lAdgFPJjkRlV9aiOGlCStbUjQLwIHkuwH/gM4Cvzy+IKq2v/S4yQfAz5tzCVpa60Z9Kq6keQEy+9emQHOVtWlJMdHx1e9by5J2hpDrtCpqgvAhRX7Joa8qn7t5Y8lSVovPykqSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGBT0JIeTXE6ykOTkhONHkjyR5PEk80l+euNHlSStZsdaC5LMAKeA+4FF4GKS81X15NiyvwXOV1UluRf4OHDPZgwsSZpsyBX6IWChqq5U1XXgHHBkfEFVvVBVNdr8fqCQJG2pIUHfDVwd214c7ft/krwtyVeBzwC/MemJkhwb3ZKZX1paup15JUm3MCTombDvpivwqvrrqroHeCvwwUlPVFVnqmququZmZ2fXNagkaXVDgr4I7B3b3gNcu9Xiqvo88MNJdr3M2SRJ6zAk6BeBA0n2J9kJHAXOjy9I8iNJMnr8emAn8NxGDytJurU13+VSVTeSnAAeBWaAs1V1Kcnx0fHTwC8C70zybeCbwC+N/SOpJGkLrBl0gKq6AFxYse/02ONHgEc2djRJ0nr4SVFJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktTEoKAnOZzkcpKFJCcnHP+VJE+Mfr6Q5L6NH1WStJo1g55kBjgFPAAcBB5OcnDFsn8Dfqaq7gU+CJzZ6EElSasbcoV+CFioqitVdR04BxwZX1BVX6iq/xptfgnYs7FjSpLWMiTou4GrY9uLo3238i7gbyYdSHIsyXyS+aWlpeFTSpLWNCTombCvJi5Mfo7loL9/0vGqOlNVc1U1Nzs7O3xKSdKadgxYswjsHdveA1xbuSjJvcBHgQeq6rmNGU+SNNSQK/SLwIEk+5PsBI4C58cXJLkb+CTwjqr6140fU5K0ljWv0KvqRpITwKPADHC2qi4lOT46fhr4APBDwJ8kAbhRVXObN7YkaaUht1yoqgvAhRX7To89fjfw7o0dTZK0Hn5SVJKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNTEo6EkOJ7mcZCHJyQnH70nyxSTfSvK+jR9TkrSWHWstSDIDnALuBxaBi0nOV9WTY8u+DvwO8NbNGFKStLYhV+iHgIWqulJV14FzwJHxBVX1bFVdBL69CTNKkgYYEvTdwNWx7cXRPknSK8iQoGfCvrqdF0tyLMl8kvmlpaXbeQpJ0i0MCfoisHdsew9w7XZerKrOVNVcVc3Nzs7ezlNIkm5hSNAvAgeS7E+yEzgKnN/csSRJ67Xmu1yq6kaSE8CjwAxwtqouJTk+On46yauBeeAHge8keS9wsKqe37zRJUnj1gw6QFVdAC6s2Hd67PF/snwrRpI0JX5SVJKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKa2DHtAaT12HfyM9MeYcM8/aGHpj2CmjHodyCjJmkSb7lIUhMGXZKaGBT0JIeTXE6ykOTkhONJ8kej408kef3GjypJWs2a99CTzACngPuBReBikvNV9eTYsgeAA6OfNwB/OvrvpvAesiTdbMgV+iFgoaquVNV14BxwZMWaI8Cf17IvAa9K8poNnlWStIoh73LZDVwd217k5qvvSWt2A8+ML0pyDDg22nwhyeV1Tbv1dgFf28wXyCOb+ewvy6afO2zv8/fcX5HuhP/vX3urA0OCngn76jbWUFVngDMDXvMVIcl8Vc1Ne45p2M7nDtv7/D33O/fch9xyWQT2jm3vAa7dxhpJ0iYaEvSLwIEk+5PsBI4C51esOQ+8c/RulzcC36iqZ1Y+kSRp86x5y6WqbiQ5ATwKzABnq+pSkuOj46eBC8CDwALwv8Cvb97IW+qOuT20CbbzucP2Pn/P/Q6VqptudUuS7kB+UlSSmjDoktSEQZ9gra866CzJ2STPJvmXac+y1ZLsTfK5JE8luZTkPdOeaSsl+d4k/5TkK6Pz/4Npz7TVkswk+eckn572LLfDoK8w9lUHDwAHgYeTHJzuVFvqY8DhaQ8xJTeA362qHwPeCPzWNvuz/xbw5qq6D3gdcHj0rrXt5D3AU9Me4nYZ9JsN+aqDtqrq88DXpz3HNFTVM1X15dHj/2H5L/bu6U61dUZf3fHCaPOu0c+2eddEkj3AQ8BHpz3L7TLoN7vV1xhoG0myD/gJ4B+nPMqWGt1yeBx4FvhsVW2n8/8w8HvAd6Y8x20z6Dcb9DUG6ivJDwCfAN5bVc9Pe56tVFUvVtXrWP6096EkPz7lkbZEkrcAz1bVY9Oe5eUw6Dfzawy2sSR3sRzzv6yqT057nmmpqv8G/p7t8+8pbwJ+IcnTLN9mfXOSv5juSOtn0G825KsO1FCSAH8GPFVVfzjtebZaktkkrxo9/j7g54GvTnWoLVJVv19Ve6pqH8t/5/+uqn51ymOtm0FfoapuAC991cFTwMer6tJ0p9o6Sf4K+CLwo0kWk7xr2jNtoTcB72D56uzx0c+D0x5qC70G+FySJ1i+sPlsVd2Rb9/brvzovyQ14RW6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1MT/AfvsCioqR9DcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "intercept = reg.intercept_\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = reg.coef_[0]\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.20,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3061374667932135"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#tf.keras.layers.Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 50)                300       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 150)               7650      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,201\n",
      "Trainable params: 38,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN_model = keras.Sequential()\n",
    "ANN_model.add(Dense(50, input_dim = 5))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(50))\n",
    "ANN_model.add(Activation('linear'))\n",
    "ANN_model.add(Dense(1))\n",
    "ANN_model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 32ms/step - loss: 1229.9525 - val_loss: 89.8961\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 787.5444 - val_loss: 42.3950\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 272.3452 - val_loss: 5.9993\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 327.7125 - val_loss: 1.5963\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 202.6558 - val_loss: 2.0443\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 168.0544 - val_loss: 3.2333\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 91.9129 - val_loss: 3.3403\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.7043 - val_loss: 3.3986\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 78.7135 - val_loss: 2.1722\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 44.5212 - val_loss: 3.9049\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 48.9399 - val_loss: 2.1092\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 55.2225 - val_loss: 1.1580\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.5935 - val_loss: 1.0906\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 25.0389 - val_loss: 1.0636\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 24.9809 - val_loss: 1.4142\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 23.1594 - val_loss: 1.7698\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 20.5872 - val_loss: 1.3561\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 20.9563 - val_loss: 1.2950\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 21.3806 - val_loss: 1.4083\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 15.7642 - val_loss: 1.8737\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 14.7547 - val_loss: 1.5183\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.7621 - val_loss: 1.0370\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.8924 - val_loss: 0.9504\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.4005 - val_loss: 1.0798\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 8.2410 - val_loss: 1.0465\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 10.4962 - val_loss: 1.0138\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 8.2000 - val_loss: 1.0276\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.3740 - val_loss: 1.2056\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7.8301 - val_loss: 1.2427\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.0171 - val_loss: 1.1451\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6592 - val_loss: 1.0442\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9089 - val_loss: 0.9984\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3568 - val_loss: 1.0103\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2771 - val_loss: 1.0061\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.7056 - val_loss: 0.9955\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.2319 - val_loss: 1.0085\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9997 - val_loss: 1.0388\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7460 - val_loss: 1.0207\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.1624 - val_loss: 1.0601\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.2444 - val_loss: 1.0501\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5758 - val_loss: 0.9822\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.9366 - val_loss: 0.9731\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.5590 - val_loss: 0.9857\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.6162 - val_loss: 1.0026\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3047 - val_loss: 1.0155\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.2557 - val_loss: 1.0396\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.5693 - val_loss: 1.0552\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.1437 - val_loss: 1.0606\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.6251 - val_loss: 1.0571\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1842 - val_loss: 1.0510\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.0642 - val_loss: 1.0320\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.3980 - val_loss: 1.0663\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.0750 - val_loss: 1.0936\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7098 - val_loss: 1.1246\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.5295 - val_loss: 1.0863\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6563 - val_loss: 1.0309\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.4276 - val_loss: 1.0239\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2899 - val_loss: 1.0300\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9210 - val_loss: 1.0472\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3763 - val_loss: 1.0537\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4464 - val_loss: 1.0465\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6130 - val_loss: 1.0402\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9315 - val_loss: 1.0482\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.0265 - val_loss: 1.0642\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3608 - val_loss: 1.0717\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.8900 - val_loss: 1.0692\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.7670 - val_loss: 1.0695\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9570 - val_loss: 1.0551\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0899 - val_loss: 1.0440\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2662 - val_loss: 1.0285\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3844 - val_loss: 1.0130\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8141 - val_loss: 1.0080\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1422 - val_loss: 1.0223\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8610 - val_loss: 1.0416\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7345 - val_loss: 1.0430\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0409 - val_loss: 1.0374\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3729 - val_loss: 1.0131\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1586 - val_loss: 0.9990\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.6725 - val_loss: 0.9772\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1.7703 - val_loss: 0.9863\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0485 - val_loss: 1.0089\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2957 - val_loss: 0.9871\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.8353 - val_loss: 0.9950\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.9607 - val_loss: 1.0154\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3117 - val_loss: 0.9977\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2621 - val_loss: 0.9892\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3131 - val_loss: 0.9899\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4372 - val_loss: 0.9867\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.7125 - val_loss: 0.9913\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.4171 - val_loss: 0.9916\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.4221 - val_loss: 0.9906\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3776 - val_loss: 0.9939\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.3163 - val_loss: 1.0130\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6713 - val_loss: 1.0245\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.1992 - val_loss: 0.9887\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.6578 - val_loss: 0.9827\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0115 - val_loss: 0.9810\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2185 - val_loss: 0.9788\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2143 - val_loss: 0.9717\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.5800 - val_loss: 0.9687\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = ANN_model.fit(train_x, train_y, epochs = 100, batch_size = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9453\n",
      "Accuracy : 0.05472445487976074\n"
     ]
    }
   ],
   "source": [
    "result = ANN_model.evaluate(test_x, test_y)\n",
    "accuracy_ANN = 1 - result\n",
    "print(\"Accuracy : {}\".format(accuracy_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d9dd43f910>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend(['Training Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decesion Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree builds regression or classification models in the form of a tree structure. \n",
    "# Decision tree breaks down a dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "# The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree_model = DecisionTreeRegressor()\n",
    "decisionTree_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.356809\n",
      "TOEFL Score           0.066725\n",
      "University Rating     0.246380\n",
      "CGPA                  0.228710\n",
      "Research              0.101375\n",
      "Feature: 0, Score: 0.35681\n",
      "Feature: 1, Score: 0.06673\n",
      "Feature: 2, Score: 0.24638\n",
      "Feature: 3, Score: 0.22871\n",
      "Feature: 4, Score: 0.10138\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = decisionTree_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10303030303030303"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decisionTree = decisionTree_model.score(test_x, test_y)\n",
    "accuracy_decisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhus\\AppData\\Local\\Temp/ipykernel_12800/2085754441.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_model.fit(train_x, train_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33897818989211825"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForest_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "randomForest_model.fit(train_x, train_y)\n",
    "accuracy_randomforest = randomForest_model.score(test_x, test_y)\n",
    "accuracy_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.347277\n",
      "TOEFL Score           0.112142\n",
      "University Rating     0.240080\n",
      "CGPA                  0.248868\n",
      "Research              0.051632\n",
      "Feature: 0, Score: 0.34728\n",
      "Feature: 1, Score: 0.11214\n",
      "Feature: 2, Score: 0.24008\n",
      "Feature: 3, Score: 0.24887\n",
      "Feature: 4, Score: 0.05163\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = randomForest_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model to the local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename='finalized_model.pickle'\n",
    "#pickle.dump(reg,open(filename,'wb'))\n",
    "dump(randomForest_model, 'filename.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
