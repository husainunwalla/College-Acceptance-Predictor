{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "- ### The goal here is to find the chance of admission of a candidate based on his/her GRE score, TOEFL score, rating of the university in which he/she is trying to get admission,strength of the SOP,Strength of the letter of the recommendation, CGPA and the research experience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Admission_Prediction.csv\")  # importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.', axis=1, inplace=True)\n",
    "df.drop('SOP', axis=1, inplace=True)\n",
    "df.drop('LOR', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GRE Score'].fillna(df['GRE Score'].mode()[0],inplace=True)\n",
    "df['TOEFL Score'].fillna(df['TOEFL Score'].mode()[0],inplace=True)\n",
    "df['University Rating'].fillna(df['University Rating'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4.3</th>\n",
       "      <td>316.857143</td>\n",
       "      <td>105.857143</td>\n",
       "      <td>8.434286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.5</th>\n",
       "      <td>317.833333</td>\n",
       "      <td>104.833333</td>\n",
       "      <td>8.973333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.9</th>\n",
       "      <td>314.692308</td>\n",
       "      <td>95.538462</td>\n",
       "      <td>8.346154</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.6</th>\n",
       "      <td>316.000000</td>\n",
       "      <td>107.833333</td>\n",
       "      <td>7.683333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.4</th>\n",
       "      <td>306.285714</td>\n",
       "      <td>99.571429</td>\n",
       "      <td>6.808571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.6</th>\n",
       "      <td>307.750000</td>\n",
       "      <td>103.750000</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42.0</th>\n",
       "      <td>302.750000</td>\n",
       "      <td>100.625000</td>\n",
       "      <td>8.218750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.4</th>\n",
       "      <td>310.500000</td>\n",
       "      <td>105.666667</td>\n",
       "      <td>8.076667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.0</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.1</th>\n",
       "      <td>296.285714</td>\n",
       "      <td>97.428571</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.9</th>\n",
       "      <td>296.000000</td>\n",
       "      <td>99.166667</td>\n",
       "      <td>7.318333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.6</th>\n",
       "      <td>313.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.8</th>\n",
       "      <td>288.666667</td>\n",
       "      <td>96.066667</td>\n",
       "      <td>7.646000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67.0</th>\n",
       "      <td>264.428571</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>7.884286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68.5</th>\n",
       "      <td>300.666667</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>8.040000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.7</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>100.833333</td>\n",
       "      <td>6.776667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>301.285714</td>\n",
       "      <td>100.571429</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.1</th>\n",
       "      <td>215.857143</td>\n",
       "      <td>90.428571</td>\n",
       "      <td>7.688571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82.3</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.0</th>\n",
       "      <td>293.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GRE Score  TOEFL Score      CGPA  Research  \\\n",
       "University Rating                                                \n",
       "4.3                316.857143   105.857143  8.434286  0.714286   \n",
       "15.0               317.000000   110.000000  8.880000  0.000000   \n",
       "16.0               317.000000   110.000000  8.880000  0.000000   \n",
       "17.5               317.833333   104.833333  8.973333  0.666667   \n",
       "20.0               317.000000   110.000000  8.880000  0.000000   \n",
       "29.9               314.692308    95.538462  8.346154  0.461538   \n",
       "36.6               316.000000   107.833333  7.683333  0.333333   \n",
       "38.4               306.285714    99.571429  6.808571  0.428571   \n",
       "39.6               307.750000   103.750000  8.490000  0.500000   \n",
       "42.0               302.750000   100.625000  8.218750  0.750000   \n",
       "46.4               310.500000   105.666667  8.076667  0.500000   \n",
       "47.0               317.000000   110.000000  8.880000  0.000000   \n",
       "50.1               296.285714    97.428571  7.370000  0.571429   \n",
       "55.9               296.000000    99.166667  7.318333  0.333333   \n",
       "63.6               313.000000   104.000000  7.950000  0.500000   \n",
       "65.8               288.666667    96.066667  7.646000  0.533333   \n",
       "67.0               264.428571   104.000000  7.884286  0.571429   \n",
       "68.5               300.666667    98.666667  8.040000  0.500000   \n",
       "70.7               303.000000   100.833333  6.776667  0.500000   \n",
       "71.0               301.285714   100.571429  7.160000  0.428571   \n",
       "80.1               215.857143    90.428571  7.688571  0.571429   \n",
       "82.3               292.000000    87.000000  7.900000  0.000000   \n",
       "99.0               293.000000    92.000000  6.000000  0.000000   \n",
       "\n",
       "                   Chance of Admit  \n",
       "University Rating                   \n",
       "4.3                       0.428571  \n",
       "15.0                      0.000000  \n",
       "16.0                      0.000000  \n",
       "17.5                      0.500000  \n",
       "20.0                      1.000000  \n",
       "29.9                      0.461538  \n",
       "36.6                      0.500000  \n",
       "38.4                      0.285714  \n",
       "39.6                      0.750000  \n",
       "42.0                      0.500000  \n",
       "46.4                      0.500000  \n",
       "47.0                      1.000000  \n",
       "50.1                      0.571429  \n",
       "55.9                      0.500000  \n",
       "63.6                      0.250000  \n",
       "65.8                      0.466667  \n",
       "67.0                      0.571429  \n",
       "68.5                      0.500000  \n",
       "70.7                      0.500000  \n",
       "71.0                      0.571429  \n",
       "80.1                      0.571429  \n",
       "82.3                      0.333333  \n",
       "99.0                      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_university = df.groupby(by='University Rating').mean()\n",
    "df_university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Chance of Admit'],axis=1)\n",
    "y=df['Chance of Admit']\n",
    "# here we are droping the Chance of Admit and serial no, as they are not going to be used for the features \n",
    "# Chance of Admit is the target column which shows the probalility of admission for a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>110</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  CGPA  Research\n",
       "0        317          110               47.0  8.88         0\n",
       "1        317          110               16.0  8.88         0\n",
       "2        317          110                4.3  8.88         0\n",
       "3        317          110               20.0  8.88         0\n",
       "4        317          110               15.0  8.88         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head() # checking the transformed feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.50595114e-01,  6.56243559e-01, -1.47630258e-01,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.60476947e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -2.15472202e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.41675151e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  6.56243559e-01, -1.65177396e+00,\n",
       "         1.09068288e+00, -9.84731928e-01],\n",
       "       [-9.11887131e-02, -5.24086900e-01,  2.29660326e+00,\n",
       "        -1.91521827e+00, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -6.55234729e-01,  1.51162827e+00,\n",
       "        -3.49644752e-01, -9.84731928e-01],\n",
       "       [ 1.92572438e-02, -6.55234729e-01,  1.51162827e+00,\n",
       "         5.89699359e-01, -9.84731928e-01],\n",
       "       [-2.01634670e-01, -1.24539996e+00,  1.51162827e+00,\n",
       "        -3.65300488e-02, -9.84731928e-01],\n",
       "       [ 5.53079369e-01,  6.56243559e-01,  6.32644289e-01,\n",
       "        -7.82786759e-02, -9.84731928e-01],\n",
       "       [ 2.76964476e-01,  5.04414726e-04,  6.32644289e-01,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 5.60725627e-02, -2.61791243e-01,  6.32644289e-01,\n",
       "         5.79262202e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  6.56243559e-01,  6.32644289e-01,\n",
       "         1.56557352e-02, -9.84731928e-01],\n",
       "       [ 6.26710006e-01,  6.56243559e-01, -2.15472202e+00,\n",
       "         9.44562689e-01,  1.01550480e+00],\n",
       "       [ 6.45117666e-01,  8.52965302e-01, -2.15472202e+00,\n",
       "         1.68560082e+00,  1.01550480e+00],\n",
       "       [ 7.37155963e-01,  1.18083487e+00, -2.15472202e+00,\n",
       "         1.30986318e+00,  1.01550480e+00],\n",
       "       [ 3.76649032e-02, -6.55234729e-01, -2.15472202e+00,\n",
       "         3.80956223e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02,  5.04414726e-04, -2.15472202e+00,\n",
       "        -5.16639261e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04,  5.04414726e-04, -2.15472202e+00,\n",
       "        -5.16639261e-01, -9.84731928e-01],\n",
       "       [ 4.97856390e-01,  5.04414726e-04,  9.66376173e-01,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 5.60725627e-02,  5.04414726e-04,  9.66376173e-01,\n",
       "        -9.13251219e-01,  1.01550480e+00],\n",
       "       [-7.27810536e-02,  3.28373987e-01,  9.66376173e-01,\n",
       "        -5.27076418e-01,  1.01550480e+00],\n",
       "       [-5.43733941e-02, -3.27365157e-01,  9.66376173e-01,\n",
       "        -2.88587385e+00, -9.84731928e-01],\n",
       "       [ 3.76649032e-02,  6.56243559e-01,  9.66376173e-01,\n",
       "        -2.54144768e+00, -9.84731928e-01],\n",
       "       [ 9.28878817e-02, -3.27365157e-01,  9.66376173e-01,\n",
       "        -6.62759456e-01,  1.01550480e+00],\n",
       "       [ 6.81932985e-01,  9.84113131e-01, -1.53426274e+00,\n",
       "         2.07177562e+00,  1.01550480e+00],\n",
       "       [ 4.97856390e-01,  6.56243559e-01, -1.53426274e+00,\n",
       "         2.17614719e+00,  1.01550480e+00],\n",
       "       [ 5.34671709e-01,  5.25095730e-01, -1.53426274e+00,\n",
       "         1.63341504e+00,  1.01550480e+00],\n",
       "       [ 1.66518520e-01, -3.92939072e-01, -1.53426274e+00,\n",
       "        -5.58387888e-01,  1.01550480e+00],\n",
       "       [ 2.76964476e-01,  4.59521815e-01, -1.53426274e+00,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02, -3.27365157e-01, -1.53426274e+00,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 4.05818093e-01,  7.87391387e-01, -6.36476963e-01,\n",
       "        -1.40901617e-01,  1.01550480e+00],\n",
       "       [ 4.42633412e-01,  4.59521815e-01, -6.36476963e-01,\n",
       "        -4.54016320e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  1.18083487e+00, -6.36476963e-01,\n",
       "         1.06980857e+00, -9.84731928e-01],\n",
       "       [ 2.95372136e-01,  7.87391387e-01, -6.36476963e-01,\n",
       "        -1.58122925e+00, -9.84731928e-01],\n",
       "       [ 2.40149157e-01,  4.59521815e-01, -6.36476963e-01,\n",
       "        -5.37513575e-01, -9.84731928e-01],\n",
       "       [ 1.84926179e-01, -5.89660815e-01, -6.36476963e-01,\n",
       "         6.94070926e-01, -9.84731928e-01],\n",
       "       [ 3.87410433e-01,  1.04968705e+00, -9.51407051e-01,\n",
       "         1.81084670e+00, -9.84731928e-01],\n",
       "       [ 3.87410433e-01,  1.24640879e+00, -9.51407051e-01,\n",
       "         1.12199435e+00,  1.01550480e+00],\n",
       "       [ 5.16264050e-01,  3.28373987e-01, -9.51407051e-01,\n",
       "         1.14286867e+00, -9.84731928e-01],\n",
       "       [ 1.29703201e-01, -9.83104301e-01, -9.51407051e-01,\n",
       "         7.98442494e-01, -9.84731928e-01],\n",
       "       [ 4.79448731e-01,  3.28373987e-01, -9.51407051e-01,\n",
       "        -4.54016320e-01, -9.84731928e-01],\n",
       "       [ 1.92572438e-02,  3.93947901e-01, -9.51407051e-01,\n",
       "        -2.87021812e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  5.25095730e-01, -1.75832953e-01,\n",
       "         9.91529895e-02,  1.01550480e+00],\n",
       "       [ 3.69002774e-01,  6.56243559e-01, -1.75832953e-01,\n",
       "         4.33142007e-01, -9.84731928e-01],\n",
       "       [ 3.32187455e-01,  6.56243559e-01, -1.75832953e-01,\n",
       "         1.32030033e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  1.31652244e-01, -1.75832953e-01,\n",
       "        -8.71502592e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02,  3.28373987e-01, -1.75832953e-01,\n",
       "        -1.40901617e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04, -6.50694997e-02, -1.75832953e-01,\n",
       "         6.73196613e-01,  1.01550480e+00],\n",
       "       [ 1.84926179e-01,  6.56243559e-01, -3.82652712e-01,\n",
       "         1.23680308e+00,  1.01550480e+00],\n",
       "       [-2.93672967e-01,  3.28373987e-01, -3.82652712e-01,\n",
       "        -3.80956223e-01,  1.01550480e+00],\n",
       "       [ 7.44802222e-02,  3.28373987e-01, -3.82652712e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [ 2.95372136e-01,  7.21817473e-01, -3.82652712e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01,  1.31652244e-01, -3.82652712e-01,\n",
       "         2.76584655e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01, -3.27365157e-01, -3.82652712e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [-3.59657347e-02, -1.17982604e+00, -3.82652712e-01,\n",
       "         9.02814062e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -3.27365157e-01, -3.82652712e-01,\n",
       "        -2.87021812e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02,  5.04414726e-04, -1.91633693e-03,\n",
       "        -7.77568181e-01,  1.01550480e+00],\n",
       "       [ 5.60725627e-02, -3.92939072e-01, -1.91633693e-03,\n",
       "        -3.65300488e-02, -9.84731928e-01],\n",
       "       [-1.83227010e-01,  5.04414726e-04, -1.91633693e-03,\n",
       "        -2.87021812e-01, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -3.27365157e-01, -1.91633693e-03,\n",
       "        -1.08024573e+00,  1.01550480e+00],\n",
       "       [ 3.13779795e-01,  3.28373987e-01,  2.70709710e-01,\n",
       "         6.78415191e-02, -9.84731928e-01],\n",
       "       [-1.75580752e-02, -3.27365157e-01,  2.70709710e-01,\n",
       "        -3.49644752e-01,  1.01550480e+00],\n",
       "       [-1.09596373e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [-1.64819351e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "        -9.75874160e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -3.27365157e-01,  2.70709710e-01,\n",
       "        -1.18461730e+00, -9.84731928e-01],\n",
       "       [-2.38449989e-01,  5.04414726e-04,  2.70709710e-01,\n",
       "        -1.06980857e+00, -9.84731928e-01],\n",
       "       [ 2.03333838e-01,  5.04414726e-04,  8.62966294e-01,\n",
       "         2.76584655e-01,  1.01550480e+00],\n",
       "       [ 1.66518520e-01, -1.30643414e-01,  8.62966294e-01,\n",
       "         7.98442494e-01, -9.84731928e-01],\n",
       "       [ 4.24225752e-01,  5.25095730e-01,  8.62966294e-01,\n",
       "         4.85327791e-01,  1.01550480e+00],\n",
       "       [-2.93672967e-01, -3.27365157e-01,  8.62966294e-01,\n",
       "        -8.71502592e-01,  1.01550480e+00],\n",
       "       [-5.43733941e-02, -3.27365157e-01,  8.62966294e-01,\n",
       "         4.33142007e-01, -9.84731928e-01],\n",
       "       [-1.46411692e-01, -2.61791243e-01,  8.62966294e-01,\n",
       "         1.61775930e-01, -9.84731928e-01],\n",
       "       [ 3.50595114e-01,  5.04414726e-04, -9.51407051e-01,\n",
       "         3.07896125e-01,  1.01550480e+00],\n",
       "       [ 4.24225752e-01,  5.04414726e-04, -9.51407051e-01,\n",
       "        -5.74043623e-02,  1.01550480e+00],\n",
       "       [ 3.87410433e-01,  4.59521815e-01, -9.51407051e-01,\n",
       "         6.10573672e-01, -9.84731928e-01],\n",
       "       [ 1.29703201e-01, -9.83104301e-01, -9.51407051e-01,\n",
       "         1.21592877e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  5.25095730e-01, -9.51407051e-01,\n",
       "        -5.58387888e-01,  1.01550480e+00],\n",
       "       [ 3.13779795e-01, -6.55688702e+00, -9.51407051e-01,\n",
       "         1.52904347e+00, -9.84731928e-01],\n",
       "       [ 2.58556817e-01,  3.93947901e-01, -9.51407051e-01,\n",
       "        -2.45273185e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01, -2.61791243e-01, -5.51868879e-01,\n",
       "        -1.09590146e-01, -9.84731928e-01],\n",
       "       [ 4.05818093e-01,  7.21817473e-01, -5.51868879e-01,\n",
       "        -1.08024573e+00,  1.01550480e+00],\n",
       "       [ 1.48110860e-01, -1.30643414e-01, -5.51868879e-01,\n",
       "         6.78415191e-02, -9.84731928e-01],\n",
       "       [-7.27810536e-02, -9.83104301e-01, -5.51868879e-01,\n",
       "        -1.39336043e+00,  1.01550480e+00],\n",
       "       [ 2.03333838e-01,  5.25095730e-01, -5.51868879e-01,\n",
       "        -1.57079210e+00,  1.01550480e+00],\n",
       "       [-7.27810536e-02, -6.50694997e-02, -5.51868879e-01,\n",
       "        -8.71502592e-01, -9.84731928e-01],\n",
       "       [ 2.03333838e-01,  5.04414726e-04, -5.51868879e-01,\n",
       "        -2.54144768e+00, -9.84731928e-01],\n",
       "       [-1.83227010e-01, -1.30643414e-01, -1.91633693e-03,\n",
       "        -2.87021812e-01, -9.84731928e-01],\n",
       "       [-1.75580752e-02, -1.30643414e-01, -1.91633693e-03,\n",
       "         1.40901617e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01, -1.96217328e-01, -1.91633693e-03,\n",
       "        -1.06980857e+00,  1.01550480e+00],\n",
       "       [ 7.44802222e-02, -1.30643414e-01,  7.36054169e-01,\n",
       "         1.80040955e+00, -9.84731928e-01],\n",
       "       [ 2.58556817e-01,  3.28373987e-01,  7.36054169e-01,\n",
       "         1.72213087e-01, -9.84731928e-01],\n",
       "       [ 3.32187455e-01,  5.90669644e-01,  7.36054169e-01,\n",
       "        -4.74890634e-01, -9.84731928e-01],\n",
       "       [ 1.66518520e-01,  3.28373987e-01,  7.36054169e-01,\n",
       "         2.97458968e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  1.31652244e-01,  7.36054169e-01,\n",
       "        -1.35161180e+00, -9.84731928e-01],\n",
       "       [ 1.48110860e-01,  7.87391387e-01,  7.36054169e-01,\n",
       "        -5.27076418e-01,  1.01550480e+00],\n",
       "       [ 8.49584283e-04,  3.28373987e-01,  7.36054169e-01,\n",
       "         1.72213087e-01,  1.01550480e+00],\n",
       "       [ 2.58556817e-01,  7.87391387e-01,  7.36054169e-01,\n",
       "        -1.46642053e+00,  1.01550480e+00],\n",
       "       [ 2.03333838e-01,  3.28373987e-01,  1.40821839e+00,\n",
       "        -3.49644752e-01,  1.01550480e+00],\n",
       "       [ 7.44802222e-02, -9.83104301e-01,  1.40821839e+00,\n",
       "         8.08879651e-01, -9.84731928e-01],\n",
       "       [ 8.49584283e-04, -7.86382558e-01,  1.40821839e+00,\n",
       "         9.86311317e-01,  1.01550480e+00],\n",
       "       [ 3.76649032e-02, -9.83104301e-01,  1.40821839e+00,\n",
       "        -2.60928920e-02,  1.01550480e+00],\n",
       "       [ 7.44802222e-02,  1.31652244e-01,  1.40821839e+00,\n",
       "        -2.20745866e+00, -9.84731928e-01],\n",
       "       [-5.48463294e+00, -1.96671302e+00,  1.40821839e+00,\n",
       "        -2.45273185e-01, -9.84731928e-01],\n",
       "       [-5.48463294e+00, -1.30643414e-01,  1.40821839e+00,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 3.32187455e-01, -6.55688702e+00,  7.36054169e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  6.56243559e-01,  7.36054169e-01,\n",
       "         9.02814062e-01,  1.01550480e+00],\n",
       "       [ 4.05818093e-01, -9.83104301e-01,  7.36054169e-01,\n",
       "        -2.45273185e-01,  1.01550480e+00],\n",
       "       [ 1.84926179e-01, -9.83104301e-01,  7.36054169e-01,\n",
       "        -4.54016320e-01, -9.84731928e-01],\n",
       "       [-5.48463294e+00,  3.28373987e-01,  7.36054169e-01,\n",
       "        -7.04508083e-01,  1.01550480e+00],\n",
       "       [ 9.28878817e-02,  2.62800072e-01,  7.36054169e-01,\n",
       "        -1.17418014e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  2.62800072e-01,  7.36054169e-01,\n",
       "        -8.08879651e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01,  3.28373987e-01,  9.80477521e-01,\n",
       "        -1.28898886e+00,  1.01550480e+00],\n",
       "       [ 1.92572438e-02,  7.21817473e-01,  9.80477521e-01,\n",
       "        -3.65300488e-02,  1.01550480e+00],\n",
       "       [ 4.42633412e-01, -5.24086900e-01,  9.80477521e-01,\n",
       "         6.62759456e-01, -9.84731928e-01],\n",
       "       [ 3.76649032e-02, -1.30643414e-01,  9.80477521e-01,\n",
       "        -6.41885143e-01, -9.84731928e-01],\n",
       "       [-1.64819351e-01, -1.30643414e-01,  9.80477521e-01,\n",
       "        -1.46642053e+00, -9.84731928e-01],\n",
       "       [-3.48895946e-01,  3.28373987e-01,  9.80477521e-01,\n",
       "        -8.61065435e-01,  1.01550480e+00],\n",
       "       [ 2.21741498e-01, -3.27365157e-01,  9.80477521e-01,\n",
       "        -1.29942602e+00, -9.84731928e-01],\n",
       "       [ 2.95372136e-01,  9.84113131e-01,  7.92459558e-01,\n",
       "         7.35819554e-01, -9.84731928e-01],\n",
       "       [ 2.21741498e-01, -6.50694997e-02,  7.92459558e-01,\n",
       "         1.51860631e+00,  1.01550480e+00],\n",
       "       [ 2.95372136e-01,  7.21817473e-01,  7.92459558e-01,\n",
       "         1.41423474e+00, -9.84731928e-01],\n",
       "       [ 9.28878817e-02, -7.20808644e-01,  7.92459558e-01,\n",
       "        -5.79262202e-01,  1.01550480e+00],\n",
       "       [ 1.48110860e-01,  3.28373987e-01,  7.92459558e-01,\n",
       "        -7.98442494e-01,  1.01550480e+00],\n",
       "       [-5.48463294e+00,  3.28373987e-01,  7.92459558e-01,\n",
       "        -1.56557352e-02,  1.01550480e+00],\n",
       "       [ 1.11295541e-01,  2.62800072e-01,  7.92459558e-01,\n",
       "        -1.91521827e+00, -9.84731928e-01],\n",
       "       [ 1.11295541e-01,  1.97226158e-01, -4.95463490e-01,\n",
       "         9.23688376e-01,  1.01550480e+00],\n",
       "       [ 4.05818093e-01,  1.18083487e+00, -4.95463490e-01,\n",
       "         1.29942602e+00, -9.84731928e-01],\n",
       "       [ 2.21741498e-01,  6.60783291e-02, -4.95463490e-01,\n",
       "         1.72213087e-01,  1.01550480e+00],\n",
       "       [-1.75580752e-02, -4.58512986e-01, -4.95463490e-01,\n",
       "         3.39207596e-01, -9.84731928e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be only used if you want to scale the data,standize the data,if the variation is huge in the dataset\n",
    "# when we have huge variation in the data set\n",
    "# i am not changing the data , i am changing the scale only like taking logs, sqrt--not changing the actual meaning of the data set\n",
    "# variance betweeen the dataset become very low\n",
    "# machine will understand in better way this data  as having low variance in the data set\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_feature=StandardScaler()\n",
    "scaler_lablel=StandardScaler()\n",
    "scaled_data=scaler_feature.fit_transform(x)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.33,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7868583905683451"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.004019\n",
      "TOEFL Score           0.016411\n",
      "University Rating     0.018374\n",
      "CGPA                  0.555673\n",
      "Research              0.501356\n",
      "Feature: 0, Score: 0.00402\n",
      "Feature: 1, Score: 0.01641\n",
      "Feature: 2, Score: 0.01837\n",
      "Feature: 3, Score: 0.55567\n",
      "Feature: 4, Score: 0.50136\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMgUlEQVR4nO3dYYhd+VnH8e/PyQZFkYIZaEmyTdDgGmS3ljGtVFCLC9ndYlosmFVb1JYQMdqCxcY3Bemb7hsp2mgINRRRDIXWEtrIUrRSoa1mtm4Xs9vIEFcyZmWnW+26WJpm+/hi7pbr5GbmTHZm7uaZ7weGveecP/c+h2y+HE7uvZOqQpJ05/ueaQ8gSdoYBl2SmjDoktSEQZekJgy6JDWxY1ovvGvXrtq3b9+0Xl6S7kiPPfbY16pqdtKxqQV93759zM/PT+vlJemOlOTfb3XMWy6S1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxNQ+KSpp/fad/My0R9gQT3/ooWmP0JJX6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGBT0JIeTXE6ykOTkhOM/m+QbSR4f/Xxg40eVJK1mzd9YlGQGOAXcDywCF5Ocr6onVyz9h6p6yybMKEkaYMgV+iFgoaquVNV14BxwZHPHkiSt15DfKbobuDq2vQi8YcK6n0ryFeAa8L6qurRyQZJjwDGAu+++e/3TStq2uvw+Vdi836k65Ao9E/bViu0vA6+tqvuAPwY+NemJqupMVc1V1dzs7Oy6BpUkrW5I0BeBvWPbe1i+Cv+uqnq+ql4YPb4A3JVk14ZNKUla05CgXwQOJNmfZCdwFDg/viDJq5Nk9PjQ6Hmf2+hhJUm3tuY99Kq6keQE8CgwA5ytqktJjo+OnwbeDvxmkhvAN4GjVbXytowkaRMN+UfRl26jXFix7/TY448AH9nY0SRJ6+EnRSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGBT0JIeTXE6ykOTkKut+MsmLSd6+cSNKkoZYM+hJZoBTwAPAQeDhJAdvse4R4NGNHlKStLYhV+iHgIWqulJV14FzwJEJ634b+ATw7AbOJ0kaaEjQdwNXx7YXR/u+K8lu4G3A6dWeKMmxJPNJ5peWltY7qyRpFUOCngn7asX2h4H3V9WLqz1RVZ2pqrmqmpudnR04oiRpiB0D1iwCe8e29wDXVqyZA84lAdgFPJjkRlV9aiOGlCStbUjQLwIHkuwH/gM4Cvzy+IKq2v/S4yQfAz5tzCVpa60Z9Kq6keQEy+9emQHOVtWlJMdHx1e9by5J2hpDrtCpqgvAhRX7Joa8qn7t5Y8lSVovPykqSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGBT0JIeTXE6ykOTkhONHkjyR5PEk80l+euNHlSStZsdaC5LMAKeA+4FF4GKS81X15NiyvwXOV1UluRf4OHDPZgwsSZpsyBX6IWChqq5U1XXgHHBkfEFVvVBVNdr8fqCQJG2pIUHfDVwd214c7ft/krwtyVeBzwC/MemJkhwb3ZKZX1paup15JUm3MCTombDvpivwqvrrqroHeCvwwUlPVFVnqmququZmZ2fXNagkaXVDgr4I7B3b3gNcu9Xiqvo88MNJdr3M2SRJ6zAk6BeBA0n2J9kJHAXOjy9I8iNJMnr8emAn8NxGDytJurU13+VSVTeSnAAeBWaAs1V1Kcnx0fHTwC8C70zybeCbwC+N/SOpJGkLrBl0gKq6AFxYse/02ONHgEc2djRJ0nr4SVFJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktTEoKAnOZzkcpKFJCcnHP+VJE+Mfr6Q5L6NH1WStJo1g55kBjgFPAAcBB5OcnDFsn8Dfqaq7gU+CJzZ6EElSasbcoV+CFioqitVdR04BxwZX1BVX6iq/xptfgnYs7FjSpLWMiTou4GrY9uLo3238i7gbyYdSHIsyXyS+aWlpeFTSpLWNCTombCvJi5Mfo7loL9/0vGqOlNVc1U1Nzs7O3xKSdKadgxYswjsHdveA1xbuSjJvcBHgQeq6rmNGU+SNNSQK/SLwIEk+5PsBI4C58cXJLkb+CTwjqr6140fU5K0ljWv0KvqRpITwKPADHC2qi4lOT46fhr4APBDwJ8kAbhRVXObN7YkaaUht1yoqgvAhRX7To89fjfw7o0dTZK0Hn5SVJKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNTEo6EkOJ7mcZCHJyQnH70nyxSTfSvK+jR9TkrSWHWstSDIDnALuBxaBi0nOV9WTY8u+DvwO8NbNGFKStLYhV+iHgIWqulJV14FzwJHxBVX1bFVdBL69CTNKkgYYEvTdwNWx7cXRPknSK8iQoGfCvrqdF0tyLMl8kvmlpaXbeQpJ0i0MCfoisHdsew9w7XZerKrOVNVcVc3Nzs7ezlNIkm5hSNAvAgeS7E+yEzgKnN/csSRJ67Xmu1yq6kaSE8CjwAxwtqouJTk+On46yauBeeAHge8keS9wsKqe37zRJUnj1gw6QFVdAC6s2Hd67PF/snwrRpI0JX5SVJKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKa2DHtAaT12HfyM9MeYcM8/aGHpj2CmjHodyCjJmkSb7lIUhMGXZKaGBT0JIeTXE6ykOTkhONJ8kej408kef3GjypJWs2a99CTzACngPuBReBikvNV9eTYsgeAA6OfNwB/OvrvpvAesiTdbMgV+iFgoaquVNV14BxwZMWaI8Cf17IvAa9K8poNnlWStIoh73LZDVwd217k5qvvSWt2A8+ML0pyDDg22nwhyeV1Tbv1dgFf28wXyCOb+ewvy6afO2zv8/fcX5HuhP/vX3urA0OCngn76jbWUFVngDMDXvMVIcl8Vc1Ne45p2M7nDtv7/D33O/fch9xyWQT2jm3vAa7dxhpJ0iYaEvSLwIEk+5PsBI4C51esOQ+8c/RulzcC36iqZ1Y+kSRp86x5y6WqbiQ5ATwKzABnq+pSkuOj46eBC8CDwALwv8Cvb97IW+qOuT20CbbzucP2Pn/P/Q6VqptudUuS7kB+UlSSmjDoktSEQZ9gra866CzJ2STPJvmXac+y1ZLsTfK5JE8luZTkPdOeaSsl+d4k/5TkK6Pz/4Npz7TVkswk+eckn572LLfDoK8w9lUHDwAHgYeTHJzuVFvqY8DhaQ8xJTeA362qHwPeCPzWNvuz/xbw5qq6D3gdcHj0rrXt5D3AU9Me4nYZ9JsN+aqDtqrq88DXpz3HNFTVM1X15dHj/2H5L/bu6U61dUZf3fHCaPOu0c+2eddEkj3AQ8BHpz3L7TLoN7vV1xhoG0myD/gJ4B+nPMqWGt1yeBx4FvhsVW2n8/8w8HvAd6Y8x20z6Dcb9DUG6ivJDwCfAN5bVc9Pe56tVFUvVtXrWP6096EkPz7lkbZEkrcAz1bVY9Oe5eUw6Dfzawy2sSR3sRzzv6yqT057nmmpqv8G/p7t8+8pbwJ+IcnTLN9mfXOSv5juSOtn0G825KsO1FCSAH8GPFVVfzjtebZaktkkrxo9/j7g54GvTnWoLVJVv19Ve6pqH8t/5/+uqn51ymOtm0FfoapuAC991cFTwMer6tJ0p9o6Sf4K+CLwo0kWk7xr2jNtoTcB72D56uzx0c+D0x5qC70G+FySJ1i+sPlsVd2Rb9/brvzovyQ14RW6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1MT/AfvsCioqR9DcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "intercept = reg.intercept_\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = reg.coef_[0]\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.01,random_state=100)\n",
    "# finding mi c1 , m2 c2,..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the data to the linear regression model\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43.50950896388285"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "score=r2_score(reg.predict(test_x),test_y)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#tf.keras.layers.Dense\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#opt = keras.optimizers.Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                300       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               7650      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 150)               22650     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 150)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                7550      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,201\n",
      "Trainable params: 38,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ANN_model = keras.Sequential()\n",
    "ANN_model.add(Dense(50, input_dim = 5))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(50))\n",
    "ANN_model.add(Activation('linear'))\n",
    "ANN_model.add(Dense(1))\n",
    "ANN_model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 32ms/step - loss: 1838.4657 - val_loss: 1.4397\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 805.1231 - val_loss: 52.7227\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 536.8583 - val_loss: 126.0431\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 455.7800 - val_loss: 3.2422\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 257.0258 - val_loss: 1.2416\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 200.7551 - val_loss: 2.1913\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 185.5326 - val_loss: 1.2466\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 127.0771 - val_loss: 5.3493\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 103.5427 - val_loss: 2.3649\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 90.9144 - val_loss: 1.1307\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 74.9292 - val_loss: 2.4584\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 62.7980 - val_loss: 1.5777\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 64.9060 - val_loss: 1.0006\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 44.6978 - val_loss: 1.0072\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 35.4180 - val_loss: 1.4531\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 31.2869 - val_loss: 2.3889\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 34.9580 - val_loss: 3.4409\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 38.1180 - val_loss: 2.7903\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 29.5619 - val_loss: 2.4006\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 21.7967 - val_loss: 1.3680\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 19.7581 - val_loss: 1.3034\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 20.7121 - val_loss: 2.0246\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 16.4780 - val_loss: 2.7078\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 14.8060 - val_loss: 2.5728\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 17.7304 - val_loss: 1.5870\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 13.5399 - val_loss: 1.3747\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.0052 - val_loss: 1.6137\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 10.7664 - val_loss: 2.9264\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 12.7439 - val_loss: 3.6098\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 12.2945 - val_loss: 2.8719\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 8.5318 - val_loss: 2.0679\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 12.3055 - val_loss: 1.4897\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 11.4913 - val_loss: 1.0653\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.9088 - val_loss: 1.0845\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.3064 - val_loss: 1.5457\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8.8893 - val_loss: 2.1551\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9440 - val_loss: 1.7922\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.3646 - val_loss: 1.3855\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.6384 - val_loss: 1.2700\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0295 - val_loss: 1.1456\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.8464 - val_loss: 1.0346\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.6234 - val_loss: 1.0213\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.6753 - val_loss: 0.9754\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1002 - val_loss: 0.9664\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.5662 - val_loss: 0.9821\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.8285 - val_loss: 1.0042\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.3189 - val_loss: 0.9926\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9007 - val_loss: 0.9707\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 4.1918 - val_loss: 0.9648\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6152 - val_loss: 0.9621\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0635 - val_loss: 1.0126\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0685 - val_loss: 1.0480\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3.6480 - val_loss: 1.0293\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.6134 - val_loss: 0.9662\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.1403 - val_loss: 0.9966\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5287 - val_loss: 1.0371\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6863 - val_loss: 1.0289\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1740 - val_loss: 0.9751\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3895 - val_loss: 0.9646\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7266 - val_loss: 0.9670\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0757 - val_loss: 0.9875\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8635 - val_loss: 0.9925\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1623 - val_loss: 0.9700\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.4136 - val_loss: 0.9602\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8643 - val_loss: 0.9741\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3957 - val_loss: 0.9881\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1067 - val_loss: 0.9631\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1071 - val_loss: 0.9564\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0229 - val_loss: 0.9582\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5943 - val_loss: 0.9558\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.7500 - val_loss: 0.9635\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0033 - val_loss: 0.9574\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.8645 - val_loss: 0.9583\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.1588 - val_loss: 0.9629\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9837 - val_loss: 0.9842\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.1603 - val_loss: 0.9699\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.9786 - val_loss: 0.9625\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.4546 - val_loss: 0.9689\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9118 - val_loss: 0.9780\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8404 - val_loss: 0.9651\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0966 - val_loss: 0.9629\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8255 - val_loss: 0.9761\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3.0337 - val_loss: 0.9696\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5054 - val_loss: 0.9683\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6260 - val_loss: 0.9688\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3424 - val_loss: 0.9740\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5095 - val_loss: 0.9710\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6958 - val_loss: 0.9811\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4711 - val_loss: 0.9736\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5047 - val_loss: 1.0368\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9662 - val_loss: 1.0735\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8287 - val_loss: 1.0260\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.5663 - val_loss: 0.9752\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4907 - val_loss: 0.9756\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7613 - val_loss: 0.9898\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7406 - val_loss: 0.9981\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7525 - val_loss: 1.0082\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.8202 - val_loss: 1.0540\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8324 - val_loss: 1.0102\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9034 - val_loss: 0.9795\n"
     ]
    }
   ],
   "source": [
    "epochs_hist = ANN_model.fit(train_x, train_y, epochs = 100, batch_size = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9934\n",
      "Accuracy : 0.006557822227478027\n"
     ]
    }
   ],
   "source": [
    "result = ANN_model.evaluate(test_x, test_y)\n",
    "accuracy_ANN = 1 - result\n",
    "print(\"Accuracy : {}\".format(accuracy_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x226eb9e1940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend(['Training Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decesion Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree builds regression or classification models in the form of a tree structure. \n",
    "# Decision tree breaks down a dataset into smaller subsets while at the same time an associated decision tree is incrementally developed. \n",
    "# The final result is a tree with decision nodes and leaf nodes.\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree_model = DecisionTreeRegressor()\n",
    "decisionTree_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.354048\n",
      "TOEFL Score           0.127480\n",
      "University Rating     0.182991\n",
      "CGPA                  0.256511\n",
      "Research              0.078970\n",
      "Feature: 0, Score: 0.35405\n",
      "Feature: 1, Score: 0.12748\n",
      "Feature: 2, Score: 0.18299\n",
      "Feature: 3, Score: 0.25651\n",
      "Feature: 4, Score: 0.07897\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = decisionTree_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_decisionTree = decisionTree_model.score(test_x, test_y)\n",
    "accuracy_decisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhus\\AppData\\Local\\Temp/ipykernel_11860/2085754441.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_model.fit(train_x, train_y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18339444444444464"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "randomForest_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "randomForest_model.fit(train_x, train_y)\n",
    "accuracy_randomforest = randomForest_model.score(test_x, test_y)\n",
    "accuracy_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   coefficient\n",
      "GRE Score             0.358395\n",
      "TOEFL Score           0.109445\n",
      "University Rating     0.219359\n",
      "CGPA                  0.252653\n",
      "Research              0.060148\n",
      "Feature: 0, Score: 0.35840\n",
      "Feature: 1, Score: 0.10944\n",
      "Feature: 2, Score: 0.21936\n",
      "Feature: 3, Score: 0.25265\n",
      "Feature: 4, Score: 0.06015\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature Importancce testing\n",
    "dfx = df.drop('Chance of Admit' , axis=1)\n",
    "importance = randomForest_model.feature_importances_\n",
    "features = pd.DataFrame(importance, dfx.columns, columns=['coefficient'])\n",
    "print(features)\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model to the local file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filename='finalized_model.pickle'\n",
    "#pickle.dump(reg,open(filename,'wb'))\n",
    "dump(randomForest_model, 'filename.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
